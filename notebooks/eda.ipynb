{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analise exploratÃ³ria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 10:19:28.637726: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-28 10:19:28.637750: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "parent = Path().absolute().parents[0].as_posix()\n",
    "\n",
    "sys.path.insert(0, parent)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import yake\n",
    "import spacy\n",
    "import pickle\n",
    "\n",
    "from nlpiper.core import Compose\n",
    "from nlpiper.transformers import cleaners\n",
    "from nlpiper.core import Document\n",
    "\n",
    "\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim import models \n",
    "\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from resources.stopwords import WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_raw = pd.read_csv('../data/scraping_data_v2.csv.gz', compression='gzip')\n",
    "data_cleaned = pd.read_csv('../data/processed/docs_cleaned_w_categories.csv.gz', compression='gzip')\n",
    "publico_articles = pd.read_csv('../data/processed/publico_docs_cleaned_w_keywords.csv.gz', compression='gzip')\n",
    "data_political_parties = pd.read_csv('../data/scraping_political_parties.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "observador.pt    147591\n",
       "expresso.pt       13037\n",
       "publico.pt         6054\n",
       "jn.pt              5678\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw[data_raw.year >= 2014].source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>year</th>\n",
       "      <th>tstamp</th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141004011519</td>\n",
       "      <td>https://arquivo.pt/wayback/20141004011519/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003170733</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003170733/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141016071819</td>\n",
       "      <td>https://arquivo.pt/wayback/20141016071819/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141016071101</td>\n",
       "      <td>https://arquivo.pt/wayback/20141016071101/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141016064106</td>\n",
       "      <td>https://arquivo.pt/wayback/20141016064106/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141021235743</td>\n",
       "      <td>https://arquivo.pt/wayback/20141021235743/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141004005435</td>\n",
       "      <td>https://arquivo.pt/wayback/20141004005435/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1411</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003174041</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003174041/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003143310</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003143310/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003151457</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003151457/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141022003514</td>\n",
       "      <td>https://arquivo.pt/wayback/20141022003514/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1415</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003190822</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003190822/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141022011511</td>\n",
       "      <td>https://arquivo.pt/wayback/20141022011511/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141004001958</td>\n",
       "      <td>https://arquivo.pt/wayback/20141004001958/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141016064824</td>\n",
       "      <td>https://arquivo.pt/wayback/20141016064824/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141004011125</td>\n",
       "      <td>https://arquivo.pt/wayback/20141004011125/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141016065853</td>\n",
       "      <td>https://arquivo.pt/wayback/20141016065853/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141022004340</td>\n",
       "      <td>https://arquivo.pt/wayback/20141022004340/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141022005224</td>\n",
       "      <td>https://arquivo.pt/wayback/20141022005224/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141004011552</td>\n",
       "      <td>https://arquivo.pt/wayback/20141004011552/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20157</th>\n",
       "      <td>Porto</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141022004101</td>\n",
       "      <td>https://arquivo.pt/wayback/20141022004101/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20158</th>\n",
       "      <td>Porto</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141016065607</td>\n",
       "      <td>https://arquivo.pt/wayback/20141016065607/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20159</th>\n",
       "      <td>Porto</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003170619</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003170619/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160</th>\n",
       "      <td>Porto</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141022001302</td>\n",
       "      <td>https://arquivo.pt/wayback/20141022001302/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20161</th>\n",
       "      <td>Porto</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141016084554</td>\n",
       "      <td>https://arquivo.pt/wayback/20141016084554/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20162</th>\n",
       "      <td>Porto</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003152117</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003152117/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20163</th>\n",
       "      <td>Porto</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141022010838</td>\n",
       "      <td>https://arquivo.pt/wayback/20141022010838/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48265</th>\n",
       "      <td>Braga</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141022002035</td>\n",
       "      <td>https://arquivo.pt/wayback/20141022002035/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48266</th>\n",
       "      <td>Braga</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141004002048</td>\n",
       "      <td>https://arquivo.pt/wayback/20141004002048/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48267</th>\n",
       "      <td>Braga</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003155912</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003155912/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60061</th>\n",
       "      <td>Aveiro</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141016075153</td>\n",
       "      <td>https://arquivo.pt/wayback/20141016075153/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68683</th>\n",
       "      <td>Faro</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003142949</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003142949/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68684</th>\n",
       "      <td>Faro</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003143057</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003143057/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68685</th>\n",
       "      <td>Faro</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003202138</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003202138/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76250</th>\n",
       "      <td>Leiria</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141016084554</td>\n",
       "      <td>https://arquivo.pt/wayback/20141016084554/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94040</th>\n",
       "      <td>Coimbra</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003135721</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003135721/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94041</th>\n",
       "      <td>Coimbra</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003221244</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003221244/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94042</th>\n",
       "      <td>Coimbra</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003164551</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003164551/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120084</th>\n",
       "      <td>Vila Real</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003165609</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003165609/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154193</th>\n",
       "      <td>Guarda</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141021233750</td>\n",
       "      <td>https://arquivo.pt/wayback/20141021233750/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173664</th>\n",
       "      <td>Portalegre</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003193119</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003193119/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              city                  title  \\\n",
       "1404        Lisboa  301 Moved Permanently   \n",
       "1405        Lisboa  301 Moved Permanently   \n",
       "1406        Lisboa  301 Moved Permanently   \n",
       "1407        Lisboa  301 Moved Permanently   \n",
       "1408        Lisboa  301 Moved Permanently   \n",
       "1409        Lisboa  301 Moved Permanently   \n",
       "1410        Lisboa  301 Moved Permanently   \n",
       "1411        Lisboa  301 Moved Permanently   \n",
       "1412        Lisboa  301 Moved Permanently   \n",
       "1413        Lisboa  301 Moved Permanently   \n",
       "1414        Lisboa  301 Moved Permanently   \n",
       "1415        Lisboa  301 Moved Permanently   \n",
       "1416        Lisboa  301 Moved Permanently   \n",
       "1417        Lisboa  301 Moved Permanently   \n",
       "1418        Lisboa  301 Moved Permanently   \n",
       "1419        Lisboa  301 Moved Permanently   \n",
       "1420        Lisboa  301 Moved Permanently   \n",
       "1421        Lisboa  301 Moved Permanently   \n",
       "1422        Lisboa  301 Moved Permanently   \n",
       "1423        Lisboa  301 Moved Permanently   \n",
       "20157        Porto  301 Moved Permanently   \n",
       "20158        Porto  301 Moved Permanently   \n",
       "20159        Porto  301 Moved Permanently   \n",
       "20160        Porto  301 Moved Permanently   \n",
       "20161        Porto  301 Moved Permanently   \n",
       "20162        Porto  301 Moved Permanently   \n",
       "20163        Porto  301 Moved Permanently   \n",
       "48265        Braga  301 Moved Permanently   \n",
       "48266        Braga  301 Moved Permanently   \n",
       "48267        Braga  301 Moved Permanently   \n",
       "60061       Aveiro  301 Moved Permanently   \n",
       "68683         Faro  301 Moved Permanently   \n",
       "68684         Faro  301 Moved Permanently   \n",
       "68685         Faro  301 Moved Permanently   \n",
       "76250       Leiria  301 Moved Permanently   \n",
       "94040      Coimbra  301 Moved Permanently   \n",
       "94041      Coimbra  301 Moved Permanently   \n",
       "94042      Coimbra  301 Moved Permanently   \n",
       "120084   Vila Real  301 Moved Permanently   \n",
       "154193      Guarda  301 Moved Permanently   \n",
       "173664  Portalegre  301 Moved Permanently   \n",
       "\n",
       "                                                  content  year  \\\n",
       "1404    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1405    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1406    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1407    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1408    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1409    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1410    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1411    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1412    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1413    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1414    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1415    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1416    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1417    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1418    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1419    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1420    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1421    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1422    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1423    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "20157   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "20158   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "20159   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "20160   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "20161   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "20162   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "20163   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "48265   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "48266   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "48267   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "60061   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "68683   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "68684   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "68685   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "76250   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "94040   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "94041   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "94042   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "120084  301 Moved Permanently Moved Permanently The do...  2014   \n",
       "154193  301 Moved Permanently Moved Permanently The do...  2014   \n",
       "173664  301 Moved Permanently Moved Permanently The do...  2014   \n",
       "\n",
       "                tstamp                                               link  \\\n",
       "1404    20141004011519  https://arquivo.pt/wayback/20141004011519/http...   \n",
       "1405    20141003170733  https://arquivo.pt/wayback/20141003170733/http...   \n",
       "1406    20141016071819  https://arquivo.pt/wayback/20141016071819/http...   \n",
       "1407    20141016071101  https://arquivo.pt/wayback/20141016071101/http...   \n",
       "1408    20141016064106  https://arquivo.pt/wayback/20141016064106/http...   \n",
       "1409    20141021235743  https://arquivo.pt/wayback/20141021235743/http...   \n",
       "1410    20141004005435  https://arquivo.pt/wayback/20141004005435/http...   \n",
       "1411    20141003174041  https://arquivo.pt/wayback/20141003174041/http...   \n",
       "1412    20141003143310  https://arquivo.pt/wayback/20141003143310/http...   \n",
       "1413    20141003151457  https://arquivo.pt/wayback/20141003151457/http...   \n",
       "1414    20141022003514  https://arquivo.pt/wayback/20141022003514/http...   \n",
       "1415    20141003190822  https://arquivo.pt/wayback/20141003190822/http...   \n",
       "1416    20141022011511  https://arquivo.pt/wayback/20141022011511/http...   \n",
       "1417    20141004001958  https://arquivo.pt/wayback/20141004001958/http...   \n",
       "1418    20141016064824  https://arquivo.pt/wayback/20141016064824/http...   \n",
       "1419    20141004011125  https://arquivo.pt/wayback/20141004011125/http...   \n",
       "1420    20141016065853  https://arquivo.pt/wayback/20141016065853/http...   \n",
       "1421    20141022004340  https://arquivo.pt/wayback/20141022004340/http...   \n",
       "1422    20141022005224  https://arquivo.pt/wayback/20141022005224/http...   \n",
       "1423    20141004011552  https://arquivo.pt/wayback/20141004011552/http...   \n",
       "20157   20141022004101  https://arquivo.pt/wayback/20141022004101/http...   \n",
       "20158   20141016065607  https://arquivo.pt/wayback/20141016065607/http...   \n",
       "20159   20141003170619  https://arquivo.pt/wayback/20141003170619/http...   \n",
       "20160   20141022001302  https://arquivo.pt/wayback/20141022001302/http...   \n",
       "20161   20141016084554  https://arquivo.pt/wayback/20141016084554/http...   \n",
       "20162   20141003152117  https://arquivo.pt/wayback/20141003152117/http...   \n",
       "20163   20141022010838  https://arquivo.pt/wayback/20141022010838/http...   \n",
       "48265   20141022002035  https://arquivo.pt/wayback/20141022002035/http...   \n",
       "48266   20141004002048  https://arquivo.pt/wayback/20141004002048/http...   \n",
       "48267   20141003155912  https://arquivo.pt/wayback/20141003155912/http...   \n",
       "60061   20141016075153  https://arquivo.pt/wayback/20141016075153/http...   \n",
       "68683   20141003142949  https://arquivo.pt/wayback/20141003142949/http...   \n",
       "68684   20141003143057  https://arquivo.pt/wayback/20141003143057/http...   \n",
       "68685   20141003202138  https://arquivo.pt/wayback/20141003202138/http...   \n",
       "76250   20141016084554  https://arquivo.pt/wayback/20141016084554/http...   \n",
       "94040   20141003135721  https://arquivo.pt/wayback/20141003135721/http...   \n",
       "94041   20141003221244  https://arquivo.pt/wayback/20141003221244/http...   \n",
       "94042   20141003164551  https://arquivo.pt/wayback/20141003164551/http...   \n",
       "120084  20141003165609  https://arquivo.pt/wayback/20141003165609/http...   \n",
       "154193  20141021233750  https://arquivo.pt/wayback/20141021233750/http...   \n",
       "173664  20141003193119  https://arquivo.pt/wayback/20141003193119/http...   \n",
       "\n",
       "             source  \n",
       "1404    expresso.pt  \n",
       "1405    expresso.pt  \n",
       "1406    expresso.pt  \n",
       "1407    expresso.pt  \n",
       "1408    expresso.pt  \n",
       "1409    expresso.pt  \n",
       "1410    expresso.pt  \n",
       "1411    expresso.pt  \n",
       "1412    expresso.pt  \n",
       "1413    expresso.pt  \n",
       "1414    expresso.pt  \n",
       "1415    expresso.pt  \n",
       "1416    expresso.pt  \n",
       "1417    expresso.pt  \n",
       "1418    expresso.pt  \n",
       "1419    expresso.pt  \n",
       "1420    expresso.pt  \n",
       "1421    expresso.pt  \n",
       "1422    expresso.pt  \n",
       "1423    expresso.pt  \n",
       "20157   expresso.pt  \n",
       "20158   expresso.pt  \n",
       "20159   expresso.pt  \n",
       "20160   expresso.pt  \n",
       "20161   expresso.pt  \n",
       "20162   expresso.pt  \n",
       "20163   expresso.pt  \n",
       "48265   expresso.pt  \n",
       "48266   expresso.pt  \n",
       "48267   expresso.pt  \n",
       "60061   expresso.pt  \n",
       "68683   expresso.pt  \n",
       "68684   expresso.pt  \n",
       "68685   expresso.pt  \n",
       "76250   expresso.pt  \n",
       "94040   expresso.pt  \n",
       "94041   expresso.pt  \n",
       "94042   expresso.pt  \n",
       "120084  expresso.pt  \n",
       "154193  expresso.pt  \n",
       "173664  expresso.pt  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw[(data_raw.source == 'expresso.pt') & (data_raw.year == 2014)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "observador.pt    47262\n",
       "expresso.pt       7136\n",
       "publico.pt         522\n",
       "jn.pt               70\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_political_parties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_political_parties[(data_political_parties.city == 'Lisboa') & (data_political_parties.year==2015)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_political_parties.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>year</th>\n",
       "      <th>tstamp</th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "      <th>link_len</th>\n",
       "      <th>check</th>\n",
       "      <th>content_p</th>\n",
       "      <th>title_p</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>OceanÃ¡rio de Lisboa vai ter novo edifÃ­cio \"tra...</td>\n",
       "      <td>OceanÃ¡rio de Lisboa vai ter novo edifÃ­cio \"tra...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20140516081533</td>\n",
       "      <td>https://arquivo.pt/wayback/20140516081533/http...</td>\n",
       "      <td>publico.pt</td>\n",
       "      <td>157</td>\n",
       "      <td>True</td>\n",
       "      <td>oceanario lisboa novo edificio tranquilo  anon...</td>\n",
       "      <td>oceanario lisboa novo edificio tranquilo  anon...</td>\n",
       "      <td>Economia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>CÃ¢mara de Loures paga mais do dobro do que Lis...</td>\n",
       "      <td>CÃ¢mara de Loures paga mais do dobro do que Lis...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141023080605</td>\n",
       "      <td>https://arquivo.pt/wayback/20141023080605/http...</td>\n",
       "      <td>publico.pt</td>\n",
       "      <td>155</td>\n",
       "      <td>True</td>\n",
       "      <td>camara loures paga dobro lisboa refeicoes esco...</td>\n",
       "      <td>camara loures paga dobro lisboa refeicoes esco...</td>\n",
       "      <td>Politica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>Deputado Bacelar Gouveia candidata-se Ã  presid...</td>\n",
       "      <td>Deputado Bacelar Gouveia candidata-se Ã  presid...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141021142620</td>\n",
       "      <td>https://arquivo.pt/wayback/20141021142620/http...</td>\n",
       "      <td>publico.pt</td>\n",
       "      <td>165</td>\n",
       "      <td>True</td>\n",
       "      <td>deputado bacelar gouveia candidatase presidenc...</td>\n",
       "      <td>deputado bacelar gouveia candidatase presidenc...</td>\n",
       "      <td>Politica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>âDarth Vadersâ do blogue 31 da Armada hasteara...</td>\n",
       "      <td>âDarth Vadersâ do blogue 31 da Armada hasteara...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141021111635</td>\n",
       "      <td>https://arquivo.pt/wayback/20141021111635/http...</td>\n",
       "      <td>publico.pt</td>\n",
       "      <td>172</td>\n",
       "      <td>True</td>\n",
       "      <td>darth vaders blogue armada hastearam bandeira...</td>\n",
       "      <td>darth vaders blogue armada hastearam bandeira...</td>\n",
       "      <td>Politica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>Ordem quer que CML esclareÃ§a ranking de arquit...</td>\n",
       "      <td>Ordem quer que CML esclareÃ§a ranking de arquit...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141021180751</td>\n",
       "      <td>https://arquivo.pt/wayback/20141021180751/http...</td>\n",
       "      <td>publico.pt</td>\n",
       "      <td>162</td>\n",
       "      <td>True</td>\n",
       "      <td>ordem quer cml esclareca ranking arquitectos a...</td>\n",
       "      <td>ordem quer cml esclareca ranking arquitectos a...</td>\n",
       "      <td>Justica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     city                                              title  \\\n",
       "0  Lisboa  OceanÃ¡rio de Lisboa vai ter novo edifÃ­cio \"tra...   \n",
       "1  Lisboa  CÃ¢mara de Loures paga mais do dobro do que Lis...   \n",
       "2  Lisboa  Deputado Bacelar Gouveia candidata-se Ã  presid...   \n",
       "3  Lisboa  âDarth Vadersâ do blogue 31 da Armada hasteara...   \n",
       "4  Lisboa  Ordem quer que CML esclareÃ§a ranking de arquit...   \n",
       "\n",
       "                                             content  year          tstamp  \\\n",
       "0  OceanÃ¡rio de Lisboa vai ter novo edifÃ­cio \"tra...  2014  20140516081533   \n",
       "1  CÃ¢mara de Loures paga mais do dobro do que Lis...  2014  20141023080605   \n",
       "2  Deputado Bacelar Gouveia candidata-se Ã  presid...  2014  20141021142620   \n",
       "3  âDarth Vadersâ do blogue 31 da Armada hasteara...  2014  20141021111635   \n",
       "4  Ordem quer que CML esclareÃ§a ranking de arquit...  2014  20141021180751   \n",
       "\n",
       "                                                link      source  link_len  \\\n",
       "0  https://arquivo.pt/wayback/20140516081533/http...  publico.pt       157   \n",
       "1  https://arquivo.pt/wayback/20141023080605/http...  publico.pt       155   \n",
       "2  https://arquivo.pt/wayback/20141021142620/http...  publico.pt       165   \n",
       "3  https://arquivo.pt/wayback/20141021111635/http...  publico.pt       172   \n",
       "4  https://arquivo.pt/wayback/20141021180751/http...  publico.pt       162   \n",
       "\n",
       "   check                                          content_p  \\\n",
       "0   True  oceanario lisboa novo edificio tranquilo  anon...   \n",
       "1   True  camara loures paga dobro lisboa refeicoes esco...   \n",
       "2   True  deputado bacelar gouveia candidatase presidenc...   \n",
       "3   True   darth vaders blogue armada hastearam bandeira...   \n",
       "4   True  ordem quer cml esclareca ranking arquitectos a...   \n",
       "\n",
       "                                             title_p  category  \n",
       "0  oceanario lisboa novo edificio tranquilo  anon...  Economia  \n",
       "1  camara loures paga dobro lisboa refeicoes esco...  Politica  \n",
       "2  deputado bacelar gouveia candidatase presidenc...  Politica  \n",
       "3   darth vaders blogue armada hastearam bandeira...  Politica  \n",
       "4  ordem quer cml esclareca ranking arquitectos a...   Justica  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>main_tag</th>\n",
       "      <th>tag</th>\n",
       "      <th>title</th>\n",
       "      <th>sub_title</th>\n",
       "      <th>body</th>\n",
       "      <th>year</th>\n",
       "      <th>category</th>\n",
       "      <th>body_p</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>ciencia</td>\n",
       "      <td>HISTÃRIA</td>\n",
       "      <td>A quinta avenida do sÃ©culo XVI ficava em Lisboa</td>\n",
       "      <td>Dois quadros descobertos em 2009 originaram um...</td>\n",
       "      <td>No sÃ©culo XVI, a Rua Nova dos Mercadores era u...</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Ciencia</td>\n",
       "      <td>seculo xvi rua nova mercadores pequena babel. ...</td>\n",
       "      <td>['Rua', 'Lisboa', 'Annemarie Jordan', 'Jordan ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     city main_tag       tag                                            title  \\\n",
       "0  Lisboa  ciencia  HISTÃRIA  A quinta avenida do sÃ©culo XVI ficava em Lisboa   \n",
       "\n",
       "                                           sub_title  \\\n",
       "0  Dois quadros descobertos em 2009 originaram um...   \n",
       "\n",
       "                                                body    year category  \\\n",
       "0  No sÃ©culo XVI, a Rua Nova dos Mercadores era u...  2015.0  Ciencia   \n",
       "\n",
       "                                              body_p  \\\n",
       "0  seculo xvi rua nova mercadores pequena babel. ...   \n",
       "\n",
       "                                            keywords  \n",
       "0  ['Rua', 'Lisboa', 'Annemarie Jordan', 'Jordan ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publico_articles.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_finder(text, target_word):\n",
    "    begin = text.find(target_word)\n",
    "    end = begin + len(target_word)\n",
    "    return begin, end, target_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rua\n",
      "(17, 20, 'Rua')\n",
      "Lisboa\n",
      "(177, 183, 'Lisboa')\n",
      "Annemarie Jordan\n",
      "(550, 566, 'Annemarie Jordan')\n",
      "Jordan Gschwend\n",
      "(560, 575, 'Jordan Gschwend')\n",
      "Mercadores\n",
      "(30, 40, 'Mercadores')\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "for keyword in ast.literal_eval(publico_articles.iloc[0].keywords):\n",
    "    print(keyword)\n",
    "    print(string_finder(publico_articles.iloc[0].body, keyword))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rua', 'Lisboa', 'Annemarie', 'Jordan', 'Jordan', 'Gschwend', 'Mercadores']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = ast.literal_eval(publico_articles.iloc[0].keywords)\n",
    "keywords = [k.split(' ') for k in keywords]\n",
    "keywords = [item for sublist in keywords for item in sublist]\n",
    "keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_keyword_annotations(doc, keywords):\n",
    "    article = []\n",
    "    for word in doc.split(' '):\n",
    "        article.append(word)\n",
    "        if word in keywords:\n",
    "            article.append((word, \"#8ef\"),)\n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotated_text import annotated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_text(*article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62604, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publico_articles['source'] = ['publico.pt'] * len(publico_articles)\n",
    "all_sources = pd.concat([data_cleaned[['city', 'year', 'title', 'category', 'source']], publico_articles[['city', 'year', 'title', 'category', 'source']]])\n",
    "all_sources.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>OceanÃ¡rio de Lisboa vai ter novo edifÃ­cio \"tra...</td>\n",
       "      <td>Economia</td>\n",
       "      <td>publico.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>CÃ¢mara de Loures paga mais do dobro do que Lis...</td>\n",
       "      <td>Politica</td>\n",
       "      <td>publico.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Deputado Bacelar Gouveia candidata-se Ã  presid...</td>\n",
       "      <td>Politica</td>\n",
       "      <td>publico.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>âDarth Vadersâ do blogue 31 da Armada hasteara...</td>\n",
       "      <td>Politica</td>\n",
       "      <td>publico.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Ordem quer que CML esclareÃ§a ranking de arquit...</td>\n",
       "      <td>Justica</td>\n",
       "      <td>publico.pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     city    year                                              title  \\\n",
       "0  Lisboa  2014.0  OceanÃ¡rio de Lisboa vai ter novo edifÃ­cio \"tra...   \n",
       "1  Lisboa  2014.0  CÃ¢mara de Loures paga mais do dobro do que Lis...   \n",
       "2  Lisboa  2014.0  Deputado Bacelar Gouveia candidata-se Ã  presid...   \n",
       "3  Lisboa  2014.0  âDarth Vadersâ do blogue 31 da Armada hasteara...   \n",
       "4  Lisboa  2014.0  Ordem quer que CML esclareÃ§a ranking de arquit...   \n",
       "\n",
       "   category      source  \n",
       "0  Economia  publico.pt  \n",
       "1  Politica  publico.pt  \n",
       "2  Politica  publico.pt  \n",
       "3  Politica  publico.pt  \n",
       "4   Justica  publico.pt  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sources.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_general = all_sources.groupby(['city','year']).size().reset_index(name='N')\n",
    "subset_categories = all_sources.groupby(['city', 'category' ,'year']).size().reset_index(name='N')\n",
    "subset_articles_general = all_sources.groupby(['city', 'source','year']).size().reset_index(name='N')\n",
    "subset_articles_general_by_category = all_sources.groupby(['city', 'source', 'category','year']).size().reset_index(name='N')\n",
    "\n",
    "articles_general.to_csv('../data/dashboard/articles_general.csv', index=False)\n",
    "subset_categories.to_csv('../data/dashboard/subset_categories.csv', index=False)\n",
    "subset_articles_general.to_csv('../data/dashboard/subset_articles_general.csv', index=False)\n",
    "subset_articles_general_by_category.to_csv('../data/dashboard/subset_articles_categories.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_articles[subset_articles.year==2019]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data.source == 'publico') & (data.year == 2019)].link.iloc[-10:].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['link_len'] = data['link'].apply(lambda val: len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['link_len'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Articles Headers and Footers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Publico:\n",
    "- Continuar a ler Assinar o PÃºblico Ã© participar na construÃ§Ã£o de um paÃ­s melhor O PÃBLICO nunca foi tÃ£o lido. Todos os meses passam pelo nosso online mais de 6.5 milhÃµes de visitantes. Para nÃ³s, este nÃºmero confirma a importÃ¢ncia do nosso trabalho. Queremos produzir mais e melhor informaÃ§Ã£o, com a liberdade de sempre e sem abdicar da diversidade de opiniÃµes que enriquece uma sociedade livre. Queremos reforÃ§ar a nossa investigaÃ§Ã£o para garantir um escrutÃ­nio mais eficaz dos poderes. Precisamos que se junte a nÃ³s neste esforÃ§o. A verdade, o pluralismo, a justiÃ§a, a solidariedade ou a abertura ao mundo sÃ£o valores que partilhamos consigo. Sinta-se ainda mais parte deste projecto cÃ­vico. Pense bem, pense PÃºblico. Assine jÃ¡ TÃ³picos Local Transportes Lisboa transporte rodoviÃ¡rio Ãrea Metropolitana de Lisboa Loures Odivelas Vila Franca de Xira Alcochete Almada Amadora Barreiro Cascais Mafra Moita Montijo Oeiras Palmela Seixal Sesimbra SetÃºbal Sintra Partilhar notÃ­cia 1 partilhas Partilhar no Facebook Partilhar no Twitter Partilhar no WhatsApp Partilhar no Messenger Partilhar no Google+ Partilhar no LinkedIn Partilhar no Pinterest Enviar por email Imprimir Guardar Comentar Sugerir correcÃ§Ã£o Ã ComentÃ¡rios Aprovados 0 Pendentes 0 NÃ£o hÃ¡ comentÃ¡rios Seja o primeiro a comentar. Mais comentÃ¡rios NÃ£o hÃ¡ comentÃ¡rios pendentes Em destaque Mais artigos A carregar... PÃºblico Siga-nos Newsletters Facebook Twitter Instagram LinkedIn YouTube RSS Actualidade PolÃ­tica Sociedade Local Economia Mundo Cultura Desporto CiÃªncia Tecnologia OpiniÃ£o PGlobal MultimÃ©dia Podcasts SecÃ§Ãµes P2 Ãpsilon Culto Fugas P3 Cidades Inimigo PÃºblico Lazer Cinecartaz Guia do Lazer ProgramaÃ§Ã£o de TV Quiosque AplicaÃ§Ãµes Loja Iniciativas Novos Projectos ServiÃ§os ImobiliÃ¡rio Sobre Ficha TÃ©cnica Estatuto Editorial Autores Contactos Provedor do Leitor PÃºblico+ Publicidade Assinaturas Assinar ConteÃºdos exclusivos Descontos para assinantes EdiÃ§Ã£o impressa CartÃ£o PÃºblico Email marketing por @ 2019 PÃBLICO ComunicaÃ§Ã£o Social SA Ajuda Termos e CondiÃ§Ãµes PolÃ­tica de Privacidade Principais Fluxos Financeiros Estrutura Accionista A Mensagem NÃ³nio Ir para o conteÃºdo Ir para navegaÃ§Ã£o principal Ã Pesquise no PÃºblico Ã Conta Entrar Pesquisar EdiÃ§Ã£o impressa Assinar A minha conta Biblioteca Perfil pÃºblico ModeraÃ§Ã£o CartÃ£o PÃºblico EdiÃ§Ã£o Impressa ConteÃºdos exclusivos Sair Em destaque Ambiente SaÃºde Demografia EUA IncÃªndios Ãgua Actualidade PolÃ­tica Sociedade Local Economia Mundo Cultura Desporto CiÃªncia Tecnologia OpiniÃ£o PGlobal MultimÃ©dia Podcasts Cidades SecÃ§Ãµes P2 Ãpsilon Culto Fugas P3 Cidades Bartoon Inimigo PÃºblico Lazer Cinecartaz Guia do Lazer ProgramaÃ§Ã£o de TV Siga-nos Newsletters Facebook Twitter Instagram LinkedIn YouTube RSS Assinaturas Assinar ConteÃºdos exclusivos EdiÃ§Ã£o impressa Descontos para assinantes CartÃ£o PÃºblico ServiÃ§os Emprego ImobiliÃ¡rio Quiosque AplicaÃ§Ãµes Loja Iniciativas Novos Projectos Sobre Ficha TÃ©cnica Estatuto Editorial Autores Contactos Provedor do Leitor PÃºblico+ Publicidade Entrar Email Palavra-chave A sua conta nÃ£o se encontra ativa. Clique aqui para receber um e-mail de ativaÃ§Ã£o de conta. Esqueceu-se da sua palavra-chave? Lembrar-se dos meus dados? NÃ£o tem uma conta? Registe-se gratuitamente Ã Ã Ã\n",
    "- Assine jÃ¡ PÃºblico Â© 2015 PÃºblico ComunicaÃ§Ã£o Social SA Facebook Twitter Google+ RSS Email marketing por Mapa do site SecÃ§Ãµes Portugal Economia Mundo Cultura-Ãpsilon Desporto CiÃªncia Tecnologia OpiniÃ£o MultimÃ©dia EdiÃ§Ã£o Impressa TÃ³picos Sites PÃºblico 2 Fugas Life&Style P3 Ãpsilon Cinecartaz Guia do Lazer Inimigo PÃºblico ServiÃ§os Meteorologia Loja Emprego Jogos TV Classificados ImobiliÃ¡rio Iniciativas Novos projectos QUIOSQUE PÃBLICO Assinaturas AplicaÃ§Ãµes Mobile Sites Mobile Tablet Kindle InformaÃ§Ãµes Novo site Contactos Ficha TÃ©cnica Autores Ajuda ComentÃ¡rios e InquÃ©ritos PÃºblico+ Provedor do Leitor Termos e CondiÃ§Ãµes PolÃ­tica de Privacidade Publicidade 30 dias apenas 1â¬ * Assine o PÃºblico Online e continue a ler e a pensar sem limites. Ao atingir o limite de artigos do PÃºblico Online mostrou como Ã© importante para si a excelÃªncia e qualidade do jornalismo em Portugal. * Para pagamentos por Visa/PayPal/dÃ©bito directo. Restantes meses â¬9,99/cada. Assine jÃ¡ e leia o PÃºblico durante 30 dias por apenas 1â¬. JÃ¡ Ã© assinante? Inicie a sessÃ£o Perguntas Frequentes NÃ³s Ligamos-lhe Apoio Online 8 semanas apenas 0,99â¬ * Para novos assinantes Assine o PÃºblico Online e continue a ler e a pensar sem limites. Ao atingir o limite de artigos do PÃºblico Online mostrou como Ã© importante para si a excelÃªncia e qualidade do jornalismo em Portugal. * Para pagamentos por Visa/PayPal/dÃ©bito directo. Restantes meses â¬9,99/cada. Sem perÃ­odo de fidelizaÃ§Ã£o. Assine jÃ¡ e leia o PÃºblico durante 8 semanas por apenas 0,99â¬. JÃ¡ Ã© assinante? Inicie a sessÃ£o Perguntas Frequentes NÃ³s Ligamos-lhe Apoio Online Aprecia o jornalismo do PÃBLICO? EntÃ£o assine o jornal e tenha o caminho livre para todos os conteÃºdos online, em qualquer plataforma (mobile, tablet ou web). NÃ£o perca as notÃ­cias, reportagens, fotografias e trabalhos multimÃ©dia que fazem do PÃBLICO um jornal premiado e lÃ­der online. Experimente por 1â¬ * no primeiro mÃªs. Assine jÃ¡ JÃ¡ Ã© assinante? Inicie sessÃ£o * Campanha para pagamentos por VISA / PayPal / dÃ©bito directo, com renovaÃ§Ã£o mensal de 9,99â¬. Tem dÃºvidas? Perguntas Frequentes Esclarecemos as suas questÃµes. Veja os videos explicativos. NÃ³s ligamos-lhe Deixe-nos o seu contato e ligamos-lhe de seguida. Apoio Online Submeta a sua questÃ£o e respondemos de imediato por chat.\n",
    "- Para continuar, inicie sessÃ£o ou registe-te jÃ¡ Iniciar SessÃ£o Entrar com o Facebook Entrar com o Twitter Ou Palavra-chave Lembrar-se de mim Esqueceu-se da sua palavra-chave? Registe-se jÃ¡ Registe-se no PÃºblico para guardar quantos artigos quiser para ler mais tarde, participar dos inquÃ©ritos, tornar-se um moderador de comentÃ¡rios e muito mais. Registar ConteÃºdo exclusivo Para continuar a ler, inicie sessÃ£o ou assine jÃ¡ Palavra-chave Lembrar-se de mim Esqueceu-se da sua palavra-chave? ASSINE O PÃBLICO ONLINE E ENTRE NO MUNDO DAS NOTICIAS SEM LIMITES Nasceu um mundo sem limites: Economia sem limites, polÃ­tica sem limites, cultura sem limites, desporto sem limites, opiniÃ£o sem limites, vÃ­deo sem limites... Entre neste mundo por apenas 1â¬*. Assine jÃ¡ * Campanha para pagamento por VISA / PayPal / dÃ©bito directo. Restantes meses: 9,99â¬/cada. PÃºblico Â© 2014 PÃºblico ComunicaÃ§Ã£o Social SA Facebook Twitter Google+ RSS Mapa do site SecÃ§Ãµes Portugal Economia Mundo Cultura Desporto CiÃªncia Tecnologia OpiniÃ£o MultimÃ©dia EdiÃ§Ã£o Impressa TÃ³picos Sites PÃºblico 2 Fugas Life&Style P3 Ãpsilon Cinecartaz Guia do Lazer Inimigo PÃºblico ServiÃ§os Meteorologia Loja Emprego Jogos TV Classificados ImobiliÃ¡rio Iniciativas QUIOSQUE PÃBLICO Assinaturas AplicaÃ§Ãµes Mobile Sites Mobile Tablet Kindle InformaÃ§Ãµes Novo site Contactos Ficha TÃ©cnica Autores Ajuda ComentÃ¡rios e InquÃ©ritos PÃºblico+ Provedor do Leitor Termos e CondiÃ§Ãµes PolÃ­tica de Privacidade Publicidade ConteÃºdo exclusivo para assinantes Para continuar a ler, faÃ§a login ou assine jÃ¡. Iniciar SessÃ£o Entrar com o Facebook Entrar com o Twitter Ou Palavra-chave Lembrar-se de mim Esqueceu-se da sua palavra-chave? Assine o PÃºblico Ligue 760 10 50 20 Assinatura DiÃ¡ria* Para usufruir de uma assinatura diÃ¡ria e ter acesso a todos os conteÃºdos exclusivos durante o dia de hoje. Tome nota do cÃ³digo e introduza-o no campo ao lado para iniciar a sessÃ£o. CondiÃ§Ãµes [+] Subscrever Outras modalidades A partir de 2,30â¬ * NÃºmero vÃ¡lido apenas para Portugal. Custo da chamada â¬0,60 + IVA. Esta assinatura Ã© vÃ¡lida atÃ© ao final do dia corrente. Assine jÃ¡ Ã Entre no Mundo das notÃ­cias sem limites Experimente por 1â¬* no primeiro mÃªs e garanta o acesso simples e imediato a todos os conteÃºdos. * Campanha para pagamento por VISA / PayPal / dÃ©bito directo. Restantes meses: 9,99â¬/cada. Leia o PÃºblico sem limites Perguntas Frequentes NÃ³s Ligamos-lhe Apoio Online\n",
    "\n",
    "Expresso:\n",
    "- Mais Artigos a carregar... Pesquisar Login Perfil Logout Para ler o SemanÃ¡rio e o DiÃ¡rio USAR CÃDIGO DisponÃ­vel na capa da Revista E ASSINAR Se ainda nÃ£o tem acesso EdiÃ§Ãµes DiÃ¡rio SemanÃ¡rio Expresso Curto Podcasts Tribuna Site Expresso InÃ­cio Ãltimas ColecionÃ¡veis MultimÃ©dia PolÃ­tica Sociedade Internacional Economia Desporto Cultura OpiniÃ£o Cartoons EstÃ¡ dito Iniciativas Carro do Ano Global Investment Challenge Entrepreneur Of The Year Classificados Emprego ImobiliÃ¡rio Siga-nos Facebook Twitter Google+ LinkedIn RSS Estatuto editorial CÃ³digo de Conduta Ficha TÃ©cnica do Expresso PolÃ­tica de cookies Termos de utilizaÃ§Ã£o PolÃ­tica de privacidade Regras da Comunidade Publicidade Contactos Lei da TransparÃªncia Assinar Cartas ao Director Loja Â© Expresso Impresa Publishing S.A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loja Siga-nos Facebook Twitter RSS Login Logout Perfil Menu Expresso Exclusivos\n",
    "- Facebook Twitter Email Whatsapp Mais Google+ Linkedin Pinterest Link:\n",
    "\n",
    "- Partilhar no Facebook Partilhar no Twitter Partilhar no Google+\n",
    "- PÃBLICO Abrir menu SecÃ§Ãµes Abrir pesquisa Pesquisa EdiÃ§Ã£o impressa PÃºblico Em destaque P2 Ãpsilon Culto Fugas P3 Cinecartaz\n",
    "- Partilhar notÃ­cia \\d+ partilhas Partilhar no Facebook Partilhar no Twitter Partilhar no WhatsApp Partilhar no Messenger Partilhar no Google+ Partilhar no LinkedIn Partilhar no Pinterest Enviar por email Guardar Comentar Entrar A minha conta Biblioteca Perfil pÃºblico ModeraÃ§Ã£o CartÃ£o PÃºblico EdiÃ§Ã£o Impressa ConteÃºdos exclusivos Sair Assine jÃ¡ SubsecÃ§Ãµes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "patterns = [\n",
    "    r\"Partilhar notÃ­cia \\d+ partilhas Partilhar no Facebook Partilhar no Twitter Partilhar no WhatsApp Partilhar no Messenger Partilhar no Google\\+ Partilhar no LinkedIn Partilhar no Pinterest Enviar por email Guardar Comentar Entrar A minha conta Biblioteca Perfil pÃºblico ModeraÃ§Ã£o CartÃ£o PÃºblico EdiÃ§Ã£o Impressa ConteÃºdos exclusivos Sair Assine jÃ¡ SubsecÃ§Ãµes\",\n",
    "    r\"Partilhar notÃ­cia \\d+ partilhas Partilhar no Facebook Partilhar no Twitter Partilhar no WhatsApp Partilhar no Messenger Partilhar no Google\\+ Partilhar no LinkedIn Partilhar no Pinterest Enviar por email Imprimir Guardar \\d+ ComentÃ¡rios\"\n",
    "\n",
    "]\n",
    "#article = re.sub(pattern, '', df[(df['source'] == 'publico') & (df['year'] == 2019)].content.iloc[5])\n",
    "#article\n",
    "# \n",
    "article = df[(df['source'] == 'publico') & (df['year'] == 2019)].content.iloc[5]\n",
    "for pattern in patterns:\n",
    "    article =  re.sub(pattern, '', article)\n",
    "\n",
    "article\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[data['link_len'] >=  data['link_len'].mean()]\n",
    "df[(df['source'] == 'publico') & (df['year'] == 2019)].content.iloc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Footers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['source'] == 'expresso') & (df['year'] == 2019)].content.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"(?=Mais Artigos a carregar...).*\"\n",
    "article = re.sub(pattern, '', df[(df['source'] == 'expresso') & (df['year'] == 2019)].content.iloc[3])\n",
    "article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs_on_tokens = np.load('../data/processed/docs_cleaned.npz', allow_pickle=True)['files']\n",
    "import pickle\n",
    "with open('../data/processed/docs_cleaned.pickle', 'rb') as handle:\n",
    "    docs_on_tokens = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs_on_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 50\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(docs_on_tokens[0:1000])\n",
    "feature_array = vectorizer.get_feature_names()\n",
    "\n",
    "tf_idf_scores = sorted(list(zip(vectorizer.get_feature_names(), \n",
    "                                             X.sum(0).getA1())), \n",
    "                                 key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print('tf_idf scores: \\n', tf_idf_scores[:top_n])\n",
    "\n",
    "\n",
    "print('idf values: \\n', sorted(list(zip(feature_array,vectorizer.idf_,)),\n",
    "       key = lambda x: x[1], reverse=True)[:top_n])\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(docs_on_tokens[0:top_n])\n",
    "feature_array = vectorizer.get_feature_names()\n",
    "print('Frequency: \\n', sorted(list(zip(vectorizer.get_feature_names(), \n",
    "                                         X.sum(0).getA1())),\n",
    "                            key=lambda x: x[1], reverse=True)[:top_n])       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\"This is very strange\",\n",
    "          \"This is very nice\"]\n",
    "vectorizer = TfidfVectorizer(norm='l2')\n",
    "corpus = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dict(zip(vectorizer.vocabulary_, vectorizer.idf_)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.link.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"pt\"\n",
    "max_ngram_size = 3\n",
    "deduplication_thresold = 0.9\n",
    "deduplication_algo = 'seqm'\n",
    "windowSize = 1\n",
    "numOfKeywords = 5\n",
    "\n",
    "custom_kw_extractor = yake.KeywordExtractor(\n",
    "    lan=language, \n",
    "    n=max_ngram_size, \n",
    "    dedupLim=deduplication_thresold, \n",
    "    dedupFunc=deduplication_algo, \n",
    "    windowsSize=windowSize, \n",
    "    top=numOfKeywords, \n",
    "    features=None\n",
    ")\n",
    "keywords = custom_kw_extractor.extract_keywords(docs[0])\n",
    "\n",
    "for kw in keywords:\n",
    "    print(kw)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_on_docs = []\n",
    "for idx in range(len(data)):\n",
    "    keywords_on_docs.append(custom_kw_extractor.extract_keywords(simple_pipeline(Document(data.content.iloc[idx].lower())).cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_kw_extractor.extract_keywords(simple_pipeline(Document(data.content.iloc[0].lower())).cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/processed/docs_keywords.pickle', 'rb') as handle:\n",
    "        docs_keywords = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = []\n",
    "for keywords in docs_keywords[-50]:\n",
    "        t.append((keywords[0], model.predict(keywords[0])[0][0]))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter([v[1] for v in t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(docs_keywords[50][-2][0])[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=docs_on_tokens, vector_size=100, window=5, min_count=1, workers=4, sg=0, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar('rei', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity('homen', 'rei')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN, KMeans, MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/processed/words_embedded.pickle', 'rb') as handle:\n",
    "    words_emb = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words_emb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [val[0] for val in words_emb]\n",
    "ks = range(2, 12)\n",
    "results = {}\n",
    "for k in ks: \n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans.fit(X)\n",
    "    results[k] = silhouette_score(X, kmeans.labels_)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_preds.labels_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=10, random_state=0)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = MiniBatchKMeans(n_clusters=20,\n",
    "                         random_state=0,\n",
    "                         batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distortions = []\n",
    "cluster_numbers = range(2, 20)\n",
    "for k in cluster_numbers:\n",
    "    k_means = KMeans(n_clusters=k, random_state=42)\n",
    "    k_means.fit(X)\n",
    "    distortions.append(sum(np.min(cdist(X, k_means.cluster_centers_, 'euclidean'), axis=1)) / len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_line = [cluster_numbers[0], cluster_numbers[-1]]\n",
    "Y_line = [distortions[0], distortions[-1]]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(cluster_numbers, distortions, 'b-')\n",
    "plt.plot(X_line, Y_line, 'r')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()\n",
    "res['Word'] = [val[1] for val in words_emb]\n",
    "res['Emb'] = [val[0] for val in words_emb]\n",
    "res['Concept'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.Concept.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[res.Concept == 8].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "model = gensim.models.Word2Vec.load('../models/trained/word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.wv.most_similar('furto', topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for concept in np.unique(kmeans_preds.labels_):\n",
    "    print('Concept:', concept)\n",
    "    print(model.wv.most_similar(positive=[np.mean(res[res.Concept==concept]['Emb'])], topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format('../models/trained/fasttext-sentiment.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.most_similar('furto', topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for concept in np.unique(kmeans_preds.labels_):\n",
    "    print('Concept:', concept)\n",
    "    print(model.most_similar(positive=[np.mean(res[res.Concept==concept]['Emb'])], topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "model = fasttext.load_model('../models/trained/fasttext-sentiment.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.get_nearest_neighbors('desporto'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all words from model\n",
    "words = model.get_words()\n",
    "\n",
    "with open('../models/trained/fasttext-sentiment.vec','w') as file_out:\n",
    "    \n",
    "    # the first line must contain number of total words and vector dimension\n",
    "    file_out.write(str(len(words)) + \" \" + str(model.get_dimension()) + \"\\n\")\n",
    "\n",
    "    # line by line, you append vectors to VEC file\n",
    "    for w in words:\n",
    "        v = model.get_word_vector(w)\n",
    "        vstr = \"\"\n",
    "        for vi in v:\n",
    "            vstr += \" \" + str(vi)\n",
    "        try:\n",
    "            file_out.write(w + vstr+'\\n')\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for concept in np.unique(kmeans_preds.labels_):\n",
    "    print('Concept:', concept)\n",
    "    print(model.most_similar(positive=[np.mean(res[res.Concept==concept]['Emb'])], topn=10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "nlp = spacy.load(\"pt_core_news_lg\")\n",
    "nlp.add_pipe('spacytextblob')\n",
    "text = 'Este restaurante Ã© uma vergonha!'\n",
    "doc = nlp(text)\n",
    "doc._.blob.polarity                         # Polarity: -0.125\n",
    "doc._.blob.subjectivity                        # Subjectivity: 0.9\n",
    "doc._.blob.sentiment_assessments.assessments   # Assessments: [(['really', 'horrible'], -1.0, 1.0, None), (['worst', '!'], -1.0, 1.0, None), (['really', 'good'], 0.7, 0.6000000000000001, None), (['happy'], 0.8, 1.0, None)]\n",
    "doc._.blob.ngrams()                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc._.blob.polarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "from textblob import TextBlob\n",
    "\n",
    "nlp = spacy.load(\"pt_core_news_lg\")\n",
    "nlp.add_pipe('spacytextblob')\n",
    "text = 'mau'\n",
    "doc = nlp(text)\n",
    "doc._.blob.polarity                            # Polarity: -0.125\n",
    "doc._.blob.subjectivity                        # Subjectivity: 0.9\n",
    "doc._.blob.sentiment_assessments.assessments   # Assessments: [(['really', 'horrible'], -1.0, 1.0, None), (['worst', '!'], -1.0, 1.0, None), (['really', 'good'], 0.7, 0.6000000000000001, None), (['happy'], 0.8, 1.0, None)]\n",
    "#doc._.blob.ngrams()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc._.blob.sentiment_assessments.assessments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/external_corpus/concatenated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(val):\n",
    "    if val < 3:\n",
    "        return 'Negative'\n",
    "    elif val == 3:\n",
    "        return 'Neutral'\n",
    "    elif val > 3:\n",
    "        return 'Positive'\n",
    "\n",
    "df['sentiment'] = df['rating'].apply(lambda val : sentiment(val))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dataset'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.sentiment == 'Neutral']['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.dataset.isin(['olist', 'b2w'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rating.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.polarity.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['polarity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [(ast.literal_eval(doc), r) for doc, r in zip(df['review_text_tokenized'].to_list(), df['sentiment'].tolist())]\n",
    "print(len(reviews))\n",
    "data = [(doc, r) for doc, r in reviews if len(doc) > 0]\n",
    "print(len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([' '.join(val[0]) for val in data])\n",
    "Y = np.array([val[1] for val in data])\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=0)\n",
    "for train_index, test_index in sss.split(X, Y ):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import linear_model\n",
    "from scipy.sparse import vstack, hstack\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = TfidfVectorizer()\n",
    "X_train_ = count_vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nb=naive_bayes.BernoulliNB()\n",
    "#nb.fit(X_train,y_train)\n",
    "#prob=nb.feature_log_prob_ #index 0 is positive\n",
    "\n",
    "#r=prob[0]-prob[1]\n",
    "\n",
    "#print('Weighing features')\n",
    "#X_train=[x.multiply(r).tocsr() for x in X_train_NB]\n",
    "#X_train=vstack(X_train)\n",
    "\n",
    "X_test_=count_vect.transform(X_test)\n",
    "#X_test=[x.multiply(r).tocsr() for x in X_test_pre]\n",
    "#X_test=vstack(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training classifier')\n",
    "\n",
    "svc = linear_model.LogisticRegression()\n",
    "svc.fit(X_train_,y_train)\n",
    "\n",
    "print('Testing classifier')\n",
    "print('Accuracy=', svc.score(X_test_, y_test)*100)\n",
    "print(classification_report(y_test, svc.predict(X_test_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = linear_model.SGDClassifier(loss='hinge', class_weight='balanced')\n",
    "svc.fit(X_train_, y_train)\n",
    "\n",
    "print('Testing classifier')\n",
    "print('Accuracy=',svc.score(X_test_, y_test)*100)\n",
    "print(classification_report(y_test, svc.predict(X_test_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame() \n",
    "df_train['sentiment'] = y_train\n",
    "df_train['review'] = X_train\n",
    "\n",
    "df_train['sentiment'] = df_train['sentiment'].apply(lambda val: f'__label__{val}')\n",
    "\n",
    "np.savetxt('olist-train.txt', df_train.values, fmt = \"%s\")\n",
    "\n",
    "print(df_train.shape)\n",
    "\n",
    "df_test = pd.DataFrame() \n",
    "df_test['sentiment'] = y_test\n",
    "df_test['review'] = X_test\n",
    "\n",
    "df_test['sentiment'] = df_test['sentiment'].apply(lambda val: f'__label__{val}')\n",
    "\n",
    "np.savetxt('olist-test.txt', df_test.values, fmt = \"%s\")\n",
    "\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(input=\"olist-train.txt\", lr=0.05, epoch=50, wordNgrams=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.test(\"olist-train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.test(\"olist-test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Pred'] = df_test['review'].apply(lambda val: model.predict(val)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(df_test['sentiment'], df_test['Pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ced3be9d1c63e918c342e50044be0791acd9298dca62153cfbef56e0b5c2b15"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
