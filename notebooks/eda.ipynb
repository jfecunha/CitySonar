{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analise exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 10:19:28.637726: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-28 10:19:28.637750: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "parent = Path().absolute().parents[0].as_posix()\n",
    "\n",
    "sys.path.insert(0, parent)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import yake\n",
    "import spacy\n",
    "import pickle\n",
    "\n",
    "from nlpiper.core import Compose\n",
    "from nlpiper.transformers import cleaners\n",
    "from nlpiper.core import Document\n",
    "\n",
    "\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim import models \n",
    "\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from resources.stopwords import WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_raw = pd.read_csv('../data/scraping_data_v2.csv.gz', compression='gzip')\n",
    "data_cleaned = pd.read_csv('../data/processed/docs_cleaned_w_categories.csv.gz', compression='gzip')\n",
    "publico_articles = pd.read_csv('../data/processed/publico_docs_cleaned_w_keywords.csv.gz', compression='gzip')\n",
    "data_political_parties = pd.read_csv('../data/scraping_political_parties.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "observador.pt    147591\n",
       "expresso.pt       13037\n",
       "publico.pt         6054\n",
       "jn.pt              5678\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw[data_raw.year >= 2014].source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>year</th>\n",
       "      <th>tstamp</th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141004011519</td>\n",
       "      <td>https://arquivo.pt/wayback/20141004011519/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003170733</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003170733/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141016071819</td>\n",
       "      <td>https://arquivo.pt/wayback/20141016071819/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141016071101</td>\n",
       "      <td>https://arquivo.pt/wayback/20141016071101/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141016064106</td>\n",
       "      <td>https://arquivo.pt/wayback/20141016064106/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141021235743</td>\n",
       "      <td>https://arquivo.pt/wayback/20141021235743/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141004005435</td>\n",
       "      <td>https://arquivo.pt/wayback/20141004005435/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1411</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003174041</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003174041/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003143310</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003143310/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003151457</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003151457/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141022003514</td>\n",
       "      <td>https://arquivo.pt/wayback/20141022003514/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1415</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003190822</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003190822/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141022011511</td>\n",
       "      <td>https://arquivo.pt/wayback/20141022011511/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141004001958</td>\n",
       "      <td>https://arquivo.pt/wayback/20141004001958/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141016064824</td>\n",
       "      <td>https://arquivo.pt/wayback/20141016064824/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141004011125</td>\n",
       "      <td>https://arquivo.pt/wayback/20141004011125/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141016065853</td>\n",
       "      <td>https://arquivo.pt/wayback/20141016065853/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141022004340</td>\n",
       "      <td>https://arquivo.pt/wayback/20141022004340/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141022005224</td>\n",
       "      <td>https://arquivo.pt/wayback/20141022005224/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141004011552</td>\n",
       "      <td>https://arquivo.pt/wayback/20141004011552/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20157</th>\n",
       "      <td>Porto</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141022004101</td>\n",
       "      <td>https://arquivo.pt/wayback/20141022004101/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20158</th>\n",
       "      <td>Porto</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141016065607</td>\n",
       "      <td>https://arquivo.pt/wayback/20141016065607/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20159</th>\n",
       "      <td>Porto</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003170619</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003170619/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160</th>\n",
       "      <td>Porto</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141022001302</td>\n",
       "      <td>https://arquivo.pt/wayback/20141022001302/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20161</th>\n",
       "      <td>Porto</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141016084554</td>\n",
       "      <td>https://arquivo.pt/wayback/20141016084554/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20162</th>\n",
       "      <td>Porto</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003152117</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003152117/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20163</th>\n",
       "      <td>Porto</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141022010838</td>\n",
       "      <td>https://arquivo.pt/wayback/20141022010838/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48265</th>\n",
       "      <td>Braga</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141022002035</td>\n",
       "      <td>https://arquivo.pt/wayback/20141022002035/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48266</th>\n",
       "      <td>Braga</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141004002048</td>\n",
       "      <td>https://arquivo.pt/wayback/20141004002048/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48267</th>\n",
       "      <td>Braga</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003155912</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003155912/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60061</th>\n",
       "      <td>Aveiro</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141016075153</td>\n",
       "      <td>https://arquivo.pt/wayback/20141016075153/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68683</th>\n",
       "      <td>Faro</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003142949</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003142949/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68684</th>\n",
       "      <td>Faro</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003143057</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003143057/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68685</th>\n",
       "      <td>Faro</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003202138</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003202138/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76250</th>\n",
       "      <td>Leiria</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141016084554</td>\n",
       "      <td>https://arquivo.pt/wayback/20141016084554/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94040</th>\n",
       "      <td>Coimbra</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003135721</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003135721/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94041</th>\n",
       "      <td>Coimbra</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003221244</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003221244/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94042</th>\n",
       "      <td>Coimbra</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003164551</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003164551/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120084</th>\n",
       "      <td>Vila Real</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003165609</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003165609/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154193</th>\n",
       "      <td>Guarda</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141021233750</td>\n",
       "      <td>https://arquivo.pt/wayback/20141021233750/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173664</th>\n",
       "      <td>Portalegre</td>\n",
       "      <td>301 Moved Permanently</td>\n",
       "      <td>301 Moved Permanently Moved Permanently The do...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141003193119</td>\n",
       "      <td>https://arquivo.pt/wayback/20141003193119/http...</td>\n",
       "      <td>expresso.pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              city                  title  \\\n",
       "1404        Lisboa  301 Moved Permanently   \n",
       "1405        Lisboa  301 Moved Permanently   \n",
       "1406        Lisboa  301 Moved Permanently   \n",
       "1407        Lisboa  301 Moved Permanently   \n",
       "1408        Lisboa  301 Moved Permanently   \n",
       "1409        Lisboa  301 Moved Permanently   \n",
       "1410        Lisboa  301 Moved Permanently   \n",
       "1411        Lisboa  301 Moved Permanently   \n",
       "1412        Lisboa  301 Moved Permanently   \n",
       "1413        Lisboa  301 Moved Permanently   \n",
       "1414        Lisboa  301 Moved Permanently   \n",
       "1415        Lisboa  301 Moved Permanently   \n",
       "1416        Lisboa  301 Moved Permanently   \n",
       "1417        Lisboa  301 Moved Permanently   \n",
       "1418        Lisboa  301 Moved Permanently   \n",
       "1419        Lisboa  301 Moved Permanently   \n",
       "1420        Lisboa  301 Moved Permanently   \n",
       "1421        Lisboa  301 Moved Permanently   \n",
       "1422        Lisboa  301 Moved Permanently   \n",
       "1423        Lisboa  301 Moved Permanently   \n",
       "20157        Porto  301 Moved Permanently   \n",
       "20158        Porto  301 Moved Permanently   \n",
       "20159        Porto  301 Moved Permanently   \n",
       "20160        Porto  301 Moved Permanently   \n",
       "20161        Porto  301 Moved Permanently   \n",
       "20162        Porto  301 Moved Permanently   \n",
       "20163        Porto  301 Moved Permanently   \n",
       "48265        Braga  301 Moved Permanently   \n",
       "48266        Braga  301 Moved Permanently   \n",
       "48267        Braga  301 Moved Permanently   \n",
       "60061       Aveiro  301 Moved Permanently   \n",
       "68683         Faro  301 Moved Permanently   \n",
       "68684         Faro  301 Moved Permanently   \n",
       "68685         Faro  301 Moved Permanently   \n",
       "76250       Leiria  301 Moved Permanently   \n",
       "94040      Coimbra  301 Moved Permanently   \n",
       "94041      Coimbra  301 Moved Permanently   \n",
       "94042      Coimbra  301 Moved Permanently   \n",
       "120084   Vila Real  301 Moved Permanently   \n",
       "154193      Guarda  301 Moved Permanently   \n",
       "173664  Portalegre  301 Moved Permanently   \n",
       "\n",
       "                                                  content  year  \\\n",
       "1404    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1405    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1406    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1407    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1408    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1409    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1410    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1411    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1412    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1413    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1414    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1415    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1416    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1417    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1418    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1419    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1420    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1421    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1422    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "1423    301 Moved Permanently Moved Permanently The do...  2014   \n",
       "20157   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "20158   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "20159   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "20160   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "20161   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "20162   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "20163   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "48265   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "48266   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "48267   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "60061   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "68683   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "68684   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "68685   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "76250   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "94040   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "94041   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "94042   301 Moved Permanently Moved Permanently The do...  2014   \n",
       "120084  301 Moved Permanently Moved Permanently The do...  2014   \n",
       "154193  301 Moved Permanently Moved Permanently The do...  2014   \n",
       "173664  301 Moved Permanently Moved Permanently The do...  2014   \n",
       "\n",
       "                tstamp                                               link  \\\n",
       "1404    20141004011519  https://arquivo.pt/wayback/20141004011519/http...   \n",
       "1405    20141003170733  https://arquivo.pt/wayback/20141003170733/http...   \n",
       "1406    20141016071819  https://arquivo.pt/wayback/20141016071819/http...   \n",
       "1407    20141016071101  https://arquivo.pt/wayback/20141016071101/http...   \n",
       "1408    20141016064106  https://arquivo.pt/wayback/20141016064106/http...   \n",
       "1409    20141021235743  https://arquivo.pt/wayback/20141021235743/http...   \n",
       "1410    20141004005435  https://arquivo.pt/wayback/20141004005435/http...   \n",
       "1411    20141003174041  https://arquivo.pt/wayback/20141003174041/http...   \n",
       "1412    20141003143310  https://arquivo.pt/wayback/20141003143310/http...   \n",
       "1413    20141003151457  https://arquivo.pt/wayback/20141003151457/http...   \n",
       "1414    20141022003514  https://arquivo.pt/wayback/20141022003514/http...   \n",
       "1415    20141003190822  https://arquivo.pt/wayback/20141003190822/http...   \n",
       "1416    20141022011511  https://arquivo.pt/wayback/20141022011511/http...   \n",
       "1417    20141004001958  https://arquivo.pt/wayback/20141004001958/http...   \n",
       "1418    20141016064824  https://arquivo.pt/wayback/20141016064824/http...   \n",
       "1419    20141004011125  https://arquivo.pt/wayback/20141004011125/http...   \n",
       "1420    20141016065853  https://arquivo.pt/wayback/20141016065853/http...   \n",
       "1421    20141022004340  https://arquivo.pt/wayback/20141022004340/http...   \n",
       "1422    20141022005224  https://arquivo.pt/wayback/20141022005224/http...   \n",
       "1423    20141004011552  https://arquivo.pt/wayback/20141004011552/http...   \n",
       "20157   20141022004101  https://arquivo.pt/wayback/20141022004101/http...   \n",
       "20158   20141016065607  https://arquivo.pt/wayback/20141016065607/http...   \n",
       "20159   20141003170619  https://arquivo.pt/wayback/20141003170619/http...   \n",
       "20160   20141022001302  https://arquivo.pt/wayback/20141022001302/http...   \n",
       "20161   20141016084554  https://arquivo.pt/wayback/20141016084554/http...   \n",
       "20162   20141003152117  https://arquivo.pt/wayback/20141003152117/http...   \n",
       "20163   20141022010838  https://arquivo.pt/wayback/20141022010838/http...   \n",
       "48265   20141022002035  https://arquivo.pt/wayback/20141022002035/http...   \n",
       "48266   20141004002048  https://arquivo.pt/wayback/20141004002048/http...   \n",
       "48267   20141003155912  https://arquivo.pt/wayback/20141003155912/http...   \n",
       "60061   20141016075153  https://arquivo.pt/wayback/20141016075153/http...   \n",
       "68683   20141003142949  https://arquivo.pt/wayback/20141003142949/http...   \n",
       "68684   20141003143057  https://arquivo.pt/wayback/20141003143057/http...   \n",
       "68685   20141003202138  https://arquivo.pt/wayback/20141003202138/http...   \n",
       "76250   20141016084554  https://arquivo.pt/wayback/20141016084554/http...   \n",
       "94040   20141003135721  https://arquivo.pt/wayback/20141003135721/http...   \n",
       "94041   20141003221244  https://arquivo.pt/wayback/20141003221244/http...   \n",
       "94042   20141003164551  https://arquivo.pt/wayback/20141003164551/http...   \n",
       "120084  20141003165609  https://arquivo.pt/wayback/20141003165609/http...   \n",
       "154193  20141021233750  https://arquivo.pt/wayback/20141021233750/http...   \n",
       "173664  20141003193119  https://arquivo.pt/wayback/20141003193119/http...   \n",
       "\n",
       "             source  \n",
       "1404    expresso.pt  \n",
       "1405    expresso.pt  \n",
       "1406    expresso.pt  \n",
       "1407    expresso.pt  \n",
       "1408    expresso.pt  \n",
       "1409    expresso.pt  \n",
       "1410    expresso.pt  \n",
       "1411    expresso.pt  \n",
       "1412    expresso.pt  \n",
       "1413    expresso.pt  \n",
       "1414    expresso.pt  \n",
       "1415    expresso.pt  \n",
       "1416    expresso.pt  \n",
       "1417    expresso.pt  \n",
       "1418    expresso.pt  \n",
       "1419    expresso.pt  \n",
       "1420    expresso.pt  \n",
       "1421    expresso.pt  \n",
       "1422    expresso.pt  \n",
       "1423    expresso.pt  \n",
       "20157   expresso.pt  \n",
       "20158   expresso.pt  \n",
       "20159   expresso.pt  \n",
       "20160   expresso.pt  \n",
       "20161   expresso.pt  \n",
       "20162   expresso.pt  \n",
       "20163   expresso.pt  \n",
       "48265   expresso.pt  \n",
       "48266   expresso.pt  \n",
       "48267   expresso.pt  \n",
       "60061   expresso.pt  \n",
       "68683   expresso.pt  \n",
       "68684   expresso.pt  \n",
       "68685   expresso.pt  \n",
       "76250   expresso.pt  \n",
       "94040   expresso.pt  \n",
       "94041   expresso.pt  \n",
       "94042   expresso.pt  \n",
       "120084  expresso.pt  \n",
       "154193  expresso.pt  \n",
       "173664  expresso.pt  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw[(data_raw.source == 'expresso.pt') & (data_raw.year == 2014)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "observador.pt    47262\n",
       "expresso.pt       7136\n",
       "publico.pt         522\n",
       "jn.pt               70\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_political_parties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_political_parties[(data_political_parties.city == 'Lisboa') & (data_political_parties.year==2015)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_political_parties.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>year</th>\n",
       "      <th>tstamp</th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "      <th>link_len</th>\n",
       "      <th>check</th>\n",
       "      <th>content_p</th>\n",
       "      <th>title_p</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>Oceanário de Lisboa vai ter novo edifício \"tra...</td>\n",
       "      <td>Oceanário de Lisboa vai ter novo edifício \"tra...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20140516081533</td>\n",
       "      <td>https://arquivo.pt/wayback/20140516081533/http...</td>\n",
       "      <td>publico.pt</td>\n",
       "      <td>157</td>\n",
       "      <td>True</td>\n",
       "      <td>oceanario lisboa novo edificio tranquilo  anon...</td>\n",
       "      <td>oceanario lisboa novo edificio tranquilo  anon...</td>\n",
       "      <td>Economia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>Câmara de Loures paga mais do dobro do que Lis...</td>\n",
       "      <td>Câmara de Loures paga mais do dobro do que Lis...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141023080605</td>\n",
       "      <td>https://arquivo.pt/wayback/20141023080605/http...</td>\n",
       "      <td>publico.pt</td>\n",
       "      <td>155</td>\n",
       "      <td>True</td>\n",
       "      <td>camara loures paga dobro lisboa refeicoes esco...</td>\n",
       "      <td>camara loures paga dobro lisboa refeicoes esco...</td>\n",
       "      <td>Politica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>Deputado Bacelar Gouveia candidata-se à presid...</td>\n",
       "      <td>Deputado Bacelar Gouveia candidata-se à presid...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141021142620</td>\n",
       "      <td>https://arquivo.pt/wayback/20141021142620/http...</td>\n",
       "      <td>publico.pt</td>\n",
       "      <td>165</td>\n",
       "      <td>True</td>\n",
       "      <td>deputado bacelar gouveia candidatase presidenc...</td>\n",
       "      <td>deputado bacelar gouveia candidatase presidenc...</td>\n",
       "      <td>Politica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>“Darth Vaders” do blogue 31 da Armada hasteara...</td>\n",
       "      <td>“Darth Vaders” do blogue 31 da Armada hasteara...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141021111635</td>\n",
       "      <td>https://arquivo.pt/wayback/20141021111635/http...</td>\n",
       "      <td>publico.pt</td>\n",
       "      <td>172</td>\n",
       "      <td>True</td>\n",
       "      <td>darth vaders blogue armada hastearam bandeira...</td>\n",
       "      <td>darth vaders blogue armada hastearam bandeira...</td>\n",
       "      <td>Politica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>Ordem quer que CML esclareça ranking de arquit...</td>\n",
       "      <td>Ordem quer que CML esclareça ranking de arquit...</td>\n",
       "      <td>2014</td>\n",
       "      <td>20141021180751</td>\n",
       "      <td>https://arquivo.pt/wayback/20141021180751/http...</td>\n",
       "      <td>publico.pt</td>\n",
       "      <td>162</td>\n",
       "      <td>True</td>\n",
       "      <td>ordem quer cml esclareca ranking arquitectos a...</td>\n",
       "      <td>ordem quer cml esclareca ranking arquitectos a...</td>\n",
       "      <td>Justica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     city                                              title  \\\n",
       "0  Lisboa  Oceanário de Lisboa vai ter novo edifício \"tra...   \n",
       "1  Lisboa  Câmara de Loures paga mais do dobro do que Lis...   \n",
       "2  Lisboa  Deputado Bacelar Gouveia candidata-se à presid...   \n",
       "3  Lisboa  “Darth Vaders” do blogue 31 da Armada hasteara...   \n",
       "4  Lisboa  Ordem quer que CML esclareça ranking de arquit...   \n",
       "\n",
       "                                             content  year          tstamp  \\\n",
       "0  Oceanário de Lisboa vai ter novo edifício \"tra...  2014  20140516081533   \n",
       "1  Câmara de Loures paga mais do dobro do que Lis...  2014  20141023080605   \n",
       "2  Deputado Bacelar Gouveia candidata-se à presid...  2014  20141021142620   \n",
       "3  “Darth Vaders” do blogue 31 da Armada hasteara...  2014  20141021111635   \n",
       "4  Ordem quer que CML esclareça ranking de arquit...  2014  20141021180751   \n",
       "\n",
       "                                                link      source  link_len  \\\n",
       "0  https://arquivo.pt/wayback/20140516081533/http...  publico.pt       157   \n",
       "1  https://arquivo.pt/wayback/20141023080605/http...  publico.pt       155   \n",
       "2  https://arquivo.pt/wayback/20141021142620/http...  publico.pt       165   \n",
       "3  https://arquivo.pt/wayback/20141021111635/http...  publico.pt       172   \n",
       "4  https://arquivo.pt/wayback/20141021180751/http...  publico.pt       162   \n",
       "\n",
       "   check                                          content_p  \\\n",
       "0   True  oceanario lisboa novo edificio tranquilo  anon...   \n",
       "1   True  camara loures paga dobro lisboa refeicoes esco...   \n",
       "2   True  deputado bacelar gouveia candidatase presidenc...   \n",
       "3   True   darth vaders blogue armada hastearam bandeira...   \n",
       "4   True  ordem quer cml esclareca ranking arquitectos a...   \n",
       "\n",
       "                                             title_p  category  \n",
       "0  oceanario lisboa novo edificio tranquilo  anon...  Economia  \n",
       "1  camara loures paga dobro lisboa refeicoes esco...  Politica  \n",
       "2  deputado bacelar gouveia candidatase presidenc...  Politica  \n",
       "3   darth vaders blogue armada hastearam bandeira...  Politica  \n",
       "4  ordem quer cml esclareca ranking arquitectos a...   Justica  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>main_tag</th>\n",
       "      <th>tag</th>\n",
       "      <th>title</th>\n",
       "      <th>sub_title</th>\n",
       "      <th>body</th>\n",
       "      <th>year</th>\n",
       "      <th>category</th>\n",
       "      <th>body_p</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>ciencia</td>\n",
       "      <td>HISTÓRIA</td>\n",
       "      <td>A quinta avenida do século XVI ficava em Lisboa</td>\n",
       "      <td>Dois quadros descobertos em 2009 originaram um...</td>\n",
       "      <td>No século XVI, a Rua Nova dos Mercadores era u...</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Ciencia</td>\n",
       "      <td>seculo xvi rua nova mercadores pequena babel. ...</td>\n",
       "      <td>['Rua', 'Lisboa', 'Annemarie Jordan', 'Jordan ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     city main_tag       tag                                            title  \\\n",
       "0  Lisboa  ciencia  HISTÓRIA  A quinta avenida do século XVI ficava em Lisboa   \n",
       "\n",
       "                                           sub_title  \\\n",
       "0  Dois quadros descobertos em 2009 originaram um...   \n",
       "\n",
       "                                                body    year category  \\\n",
       "0  No século XVI, a Rua Nova dos Mercadores era u...  2015.0  Ciencia   \n",
       "\n",
       "                                              body_p  \\\n",
       "0  seculo xvi rua nova mercadores pequena babel. ...   \n",
       "\n",
       "                                            keywords  \n",
       "0  ['Rua', 'Lisboa', 'Annemarie Jordan', 'Jordan ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publico_articles.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_finder(text, target_word):\n",
    "    begin = text.find(target_word)\n",
    "    end = begin + len(target_word)\n",
    "    return begin, end, target_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rua\n",
      "(17, 20, 'Rua')\n",
      "Lisboa\n",
      "(177, 183, 'Lisboa')\n",
      "Annemarie Jordan\n",
      "(550, 566, 'Annemarie Jordan')\n",
      "Jordan Gschwend\n",
      "(560, 575, 'Jordan Gschwend')\n",
      "Mercadores\n",
      "(30, 40, 'Mercadores')\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "for keyword in ast.literal_eval(publico_articles.iloc[0].keywords):\n",
    "    print(keyword)\n",
    "    print(string_finder(publico_articles.iloc[0].body, keyword))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rua', 'Lisboa', 'Annemarie', 'Jordan', 'Jordan', 'Gschwend', 'Mercadores']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = ast.literal_eval(publico_articles.iloc[0].keywords)\n",
    "keywords = [k.split(' ') for k in keywords]\n",
    "keywords = [item for sublist in keywords for item in sublist]\n",
    "keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_keyword_annotations(doc, keywords):\n",
    "    article = []\n",
    "    for word in doc.split(' '):\n",
    "        article.append(word)\n",
    "        if word in keywords:\n",
    "            article.append((word, \"#8ef\"),)\n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotated_text import annotated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_text(*article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62604, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publico_articles['source'] = ['publico.pt'] * len(publico_articles)\n",
    "all_sources = pd.concat([data_cleaned[['city', 'year', 'title', 'category', 'source']], publico_articles[['city', 'year', 'title', 'category', 'source']]])\n",
    "all_sources.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Oceanário de Lisboa vai ter novo edifício \"tra...</td>\n",
       "      <td>Economia</td>\n",
       "      <td>publico.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Câmara de Loures paga mais do dobro do que Lis...</td>\n",
       "      <td>Politica</td>\n",
       "      <td>publico.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Deputado Bacelar Gouveia candidata-se à presid...</td>\n",
       "      <td>Politica</td>\n",
       "      <td>publico.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>“Darth Vaders” do blogue 31 da Armada hasteara...</td>\n",
       "      <td>Politica</td>\n",
       "      <td>publico.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Ordem quer que CML esclareça ranking de arquit...</td>\n",
       "      <td>Justica</td>\n",
       "      <td>publico.pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     city    year                                              title  \\\n",
       "0  Lisboa  2014.0  Oceanário de Lisboa vai ter novo edifício \"tra...   \n",
       "1  Lisboa  2014.0  Câmara de Loures paga mais do dobro do que Lis...   \n",
       "2  Lisboa  2014.0  Deputado Bacelar Gouveia candidata-se à presid...   \n",
       "3  Lisboa  2014.0  “Darth Vaders” do blogue 31 da Armada hasteara...   \n",
       "4  Lisboa  2014.0  Ordem quer que CML esclareça ranking de arquit...   \n",
       "\n",
       "   category      source  \n",
       "0  Economia  publico.pt  \n",
       "1  Politica  publico.pt  \n",
       "2  Politica  publico.pt  \n",
       "3  Politica  publico.pt  \n",
       "4   Justica  publico.pt  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sources.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_general = all_sources.groupby(['city','year']).size().reset_index(name='N')\n",
    "subset_categories = all_sources.groupby(['city', 'category' ,'year']).size().reset_index(name='N')\n",
    "subset_articles_general = all_sources.groupby(['city', 'source','year']).size().reset_index(name='N')\n",
    "subset_articles_general_by_category = all_sources.groupby(['city', 'source', 'category','year']).size().reset_index(name='N')\n",
    "\n",
    "articles_general.to_csv('../data/dashboard/articles_general.csv', index=False)\n",
    "subset_categories.to_csv('../data/dashboard/subset_categories.csv', index=False)\n",
    "subset_articles_general.to_csv('../data/dashboard/subset_articles_general.csv', index=False)\n",
    "subset_articles_general_by_category.to_csv('../data/dashboard/subset_articles_categories.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_articles[subset_articles.year==2019]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data.source == 'publico') & (data.year == 2019)].link.iloc[-10:].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['link_len'] = data['link'].apply(lambda val: len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['link_len'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Articles Headers and Footers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Publico:\n",
    "- Continuar a ler Assinar o Público é participar na construção de um país melhor O PÚBLICO nunca foi tão lido. Todos os meses passam pelo nosso online mais de 6.5 milhões de visitantes. Para nós, este número confirma a importância do nosso trabalho. Queremos produzir mais e melhor informação, com a liberdade de sempre e sem abdicar da diversidade de opiniões que enriquece uma sociedade livre. Queremos reforçar a nossa investigação para garantir um escrutínio mais eficaz dos poderes. Precisamos que se junte a nós neste esforço. A verdade, o pluralismo, a justiça, a solidariedade ou a abertura ao mundo são valores que partilhamos consigo. Sinta-se ainda mais parte deste projecto cívico. Pense bem, pense Público. Assine já Tópicos Local Transportes Lisboa transporte rodoviário Área Metropolitana de Lisboa Loures Odivelas Vila Franca de Xira Alcochete Almada Amadora Barreiro Cascais Mafra Moita Montijo Oeiras Palmela Seixal Sesimbra Setúbal Sintra Partilhar notícia 1 partilhas Partilhar no Facebook Partilhar no Twitter Partilhar no WhatsApp Partilhar no Messenger Partilhar no Google+ Partilhar no LinkedIn Partilhar no Pinterest Enviar por email Imprimir Guardar Comentar Sugerir correcção × Comentários Aprovados 0 Pendentes 0 Não há comentários Seja o primeiro a comentar. Mais comentários Não há comentários pendentes Em destaque Mais artigos A carregar... Público Siga-nos Newsletters Facebook Twitter Instagram LinkedIn YouTube RSS Actualidade Política Sociedade Local Economia Mundo Cultura Desporto Ciência Tecnologia Opinião PGlobal Multimédia Podcasts Secções P2 Ípsilon Culto Fugas P3 Cidades Inimigo Público Lazer Cinecartaz Guia do Lazer Programação de TV Quiosque Aplicações Loja Iniciativas Novos Projectos Serviços Imobiliário Sobre Ficha Técnica Estatuto Editorial Autores Contactos Provedor do Leitor Público+ Publicidade Assinaturas Assinar Conteúdos exclusivos Descontos para assinantes Edição impressa Cartão Público Email marketing por @ 2019 PÚBLICO Comunicação Social SA Ajuda Termos e Condições Política de Privacidade Principais Fluxos Financeiros Estrutura Accionista A Mensagem Nónio Ir para o conteúdo Ir para navegação principal × Pesquise no Público × Conta Entrar Pesquisar Edição impressa Assinar A minha conta Biblioteca Perfil público Moderação Cartão Público Edição Impressa Conteúdos exclusivos Sair Em destaque Ambiente Saúde Demografia EUA Incêndios Água Actualidade Política Sociedade Local Economia Mundo Cultura Desporto Ciência Tecnologia Opinião PGlobal Multimédia Podcasts Cidades Secções P2 Ípsilon Culto Fugas P3 Cidades Bartoon Inimigo Público Lazer Cinecartaz Guia do Lazer Programação de TV Siga-nos Newsletters Facebook Twitter Instagram LinkedIn YouTube RSS Assinaturas Assinar Conteúdos exclusivos Edição impressa Descontos para assinantes Cartão Público Serviços Emprego Imobiliário Quiosque Aplicações Loja Iniciativas Novos Projectos Sobre Ficha Técnica Estatuto Editorial Autores Contactos Provedor do Leitor Público+ Publicidade Entrar Email Palavra-chave A sua conta não se encontra ativa. Clique aqui para receber um e-mail de ativação de conta. Esqueceu-se da sua palavra-chave? Lembrar-se dos meus dados? Não tem uma conta? Registe-se gratuitamente × × ×\n",
    "- Assine já Público © 2015 Público Comunicação Social SA Facebook Twitter Google+ RSS Email marketing por Mapa do site Secções Portugal Economia Mundo Cultura-Ípsilon Desporto Ciência Tecnologia Opinião Multimédia Edição Impressa Tópicos Sites Público 2 Fugas Life&Style P3 Ípsilon Cinecartaz Guia do Lazer Inimigo Público Serviços Meteorologia Loja Emprego Jogos TV Classificados Imobiliário Iniciativas Novos projectos QUIOSQUE PÚBLICO Assinaturas Aplicações Mobile Sites Mobile Tablet Kindle Informações Novo site Contactos Ficha Técnica Autores Ajuda Comentários e Inquéritos Público+ Provedor do Leitor Termos e Condições Política de Privacidade Publicidade 30 dias apenas 1€ * Assine o Público Online e continue a ler e a pensar sem limites. Ao atingir o limite de artigos do Público Online mostrou como é importante para si a excelência e qualidade do jornalismo em Portugal. * Para pagamentos por Visa/PayPal/débito directo. Restantes meses €9,99/cada. Assine já e leia o Público durante 30 dias por apenas 1€. Já é assinante? Inicie a sessão Perguntas Frequentes Nós Ligamos-lhe Apoio Online 8 semanas apenas 0,99€ * Para novos assinantes Assine o Público Online e continue a ler e a pensar sem limites. Ao atingir o limite de artigos do Público Online mostrou como é importante para si a excelência e qualidade do jornalismo em Portugal. * Para pagamentos por Visa/PayPal/débito directo. Restantes meses €9,99/cada. Sem período de fidelização. Assine já e leia o Público durante 8 semanas por apenas 0,99€. Já é assinante? Inicie a sessão Perguntas Frequentes Nós Ligamos-lhe Apoio Online Aprecia o jornalismo do PÚBLICO? Então assine o jornal e tenha o caminho livre para todos os conteúdos online, em qualquer plataforma (mobile, tablet ou web). Não perca as notícias, reportagens, fotografias e trabalhos multimédia que fazem do PÚBLICO um jornal premiado e líder online. Experimente por 1€ * no primeiro mês. Assine já Já é assinante? Inicie sessão * Campanha para pagamentos por VISA / PayPal / débito directo, com renovação mensal de 9,99€. Tem dúvidas? Perguntas Frequentes Esclarecemos as suas questões. Veja os videos explicativos. Nós ligamos-lhe Deixe-nos o seu contato e ligamos-lhe de seguida. Apoio Online Submeta a sua questão e respondemos de imediato por chat.\n",
    "- Para continuar, inicie sessão ou registe-te já Iniciar Sessão Entrar com o Facebook Entrar com o Twitter Ou Palavra-chave Lembrar-se de mim Esqueceu-se da sua palavra-chave? Registe-se já Registe-se no Público para guardar quantos artigos quiser para ler mais tarde, participar dos inquéritos, tornar-se um moderador de comentários e muito mais. Registar Conteúdo exclusivo Para continuar a ler, inicie sessão ou assine já Palavra-chave Lembrar-se de mim Esqueceu-se da sua palavra-chave? ASSINE O PÚBLICO ONLINE E ENTRE NO MUNDO DAS NOTICIAS SEM LIMITES Nasceu um mundo sem limites: Economia sem limites, política sem limites, cultura sem limites, desporto sem limites, opinião sem limites, vídeo sem limites... Entre neste mundo por apenas 1€*. Assine já * Campanha para pagamento por VISA / PayPal / débito directo. Restantes meses: 9,99€/cada. Público © 2014 Público Comunicação Social SA Facebook Twitter Google+ RSS Mapa do site Secções Portugal Economia Mundo Cultura Desporto Ciência Tecnologia Opinião Multimédia Edição Impressa Tópicos Sites Público 2 Fugas Life&Style P3 Ípsilon Cinecartaz Guia do Lazer Inimigo Público Serviços Meteorologia Loja Emprego Jogos TV Classificados Imobiliário Iniciativas QUIOSQUE PÚBLICO Assinaturas Aplicações Mobile Sites Mobile Tablet Kindle Informações Novo site Contactos Ficha Técnica Autores Ajuda Comentários e Inquéritos Público+ Provedor do Leitor Termos e Condições Política de Privacidade Publicidade Conteúdo exclusivo para assinantes Para continuar a ler, faça login ou assine já. Iniciar Sessão Entrar com o Facebook Entrar com o Twitter Ou Palavra-chave Lembrar-se de mim Esqueceu-se da sua palavra-chave? Assine o Público Ligue 760 10 50 20 Assinatura Diária* Para usufruir de uma assinatura diária e ter acesso a todos os conteúdos exclusivos durante o dia de hoje. Tome nota do código e introduza-o no campo ao lado para iniciar a sessão. Condições [+] Subscrever Outras modalidades A partir de 2,30€ * Número válido apenas para Portugal. Custo da chamada €0,60 + IVA. Esta assinatura é válida até ao final do dia corrente. Assine já × Entre no Mundo das notícias sem limites Experimente por 1€* no primeiro mês e garanta o acesso simples e imediato a todos os conteúdos. * Campanha para pagamento por VISA / PayPal / débito directo. Restantes meses: 9,99€/cada. Leia o Público sem limites Perguntas Frequentes Nós Ligamos-lhe Apoio Online\n",
    "\n",
    "Expresso:\n",
    "- Mais Artigos a carregar... Pesquisar Login Perfil Logout Para ler o Semanário e o Diário USAR CÓDIGO Disponível na capa da Revista E ASSINAR Se ainda não tem acesso Edições Diário Semanário Expresso Curto Podcasts Tribuna Site Expresso Início Últimas Colecionáveis Multimédia Política Sociedade Internacional Economia Desporto Cultura Opinião Cartoons Está dito Iniciativas Carro do Ano Global Investment Challenge Entrepreneur Of The Year Classificados Emprego Imobiliário Siga-nos Facebook Twitter Google+ LinkedIn RSS Estatuto editorial Código de Conduta Ficha Técnica do Expresso Política de cookies Termos de utilização Política de privacidade Regras da Comunidade Publicidade Contactos Lei da Transparência Assinar Cartas ao Director Loja © Expresso Impresa Publishing S.A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loja Siga-nos Facebook Twitter RSS Login Logout Perfil Menu Expresso Exclusivos\n",
    "- Facebook Twitter Email Whatsapp Mais Google+ Linkedin Pinterest Link:\n",
    "\n",
    "- Partilhar no Facebook Partilhar no Twitter Partilhar no Google+\n",
    "- PÚBLICO Abrir menu Secções Abrir pesquisa Pesquisa Edição impressa Público Em destaque P2 Ípsilon Culto Fugas P3 Cinecartaz\n",
    "- Partilhar notícia \\d+ partilhas Partilhar no Facebook Partilhar no Twitter Partilhar no WhatsApp Partilhar no Messenger Partilhar no Google+ Partilhar no LinkedIn Partilhar no Pinterest Enviar por email Guardar Comentar Entrar A minha conta Biblioteca Perfil público Moderação Cartão Público Edição Impressa Conteúdos exclusivos Sair Assine já Subsecções"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "patterns = [\n",
    "    r\"Partilhar notícia \\d+ partilhas Partilhar no Facebook Partilhar no Twitter Partilhar no WhatsApp Partilhar no Messenger Partilhar no Google\\+ Partilhar no LinkedIn Partilhar no Pinterest Enviar por email Guardar Comentar Entrar A minha conta Biblioteca Perfil público Moderação Cartão Público Edição Impressa Conteúdos exclusivos Sair Assine já Subsecções\",\n",
    "    r\"Partilhar notícia \\d+ partilhas Partilhar no Facebook Partilhar no Twitter Partilhar no WhatsApp Partilhar no Messenger Partilhar no Google\\+ Partilhar no LinkedIn Partilhar no Pinterest Enviar por email Imprimir Guardar \\d+ Comentários\"\n",
    "\n",
    "]\n",
    "#article = re.sub(pattern, '', df[(df['source'] == 'publico') & (df['year'] == 2019)].content.iloc[5])\n",
    "#article\n",
    "# \n",
    "article = df[(df['source'] == 'publico') & (df['year'] == 2019)].content.iloc[5]\n",
    "for pattern in patterns:\n",
    "    article =  re.sub(pattern, '', article)\n",
    "\n",
    "article\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[data['link_len'] >=  data['link_len'].mean()]\n",
    "df[(df['source'] == 'publico') & (df['year'] == 2019)].content.iloc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Footers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['source'] == 'expresso') & (df['year'] == 2019)].content.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"(?=Mais Artigos a carregar...).*\"\n",
    "article = re.sub(pattern, '', df[(df['source'] == 'expresso') & (df['year'] == 2019)].content.iloc[3])\n",
    "article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs_on_tokens = np.load('../data/processed/docs_cleaned.npz', allow_pickle=True)['files']\n",
    "import pickle\n",
    "with open('../data/processed/docs_cleaned.pickle', 'rb') as handle:\n",
    "    docs_on_tokens = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs_on_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 50\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(docs_on_tokens[0:1000])\n",
    "feature_array = vectorizer.get_feature_names()\n",
    "\n",
    "tf_idf_scores = sorted(list(zip(vectorizer.get_feature_names(), \n",
    "                                             X.sum(0).getA1())), \n",
    "                                 key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print('tf_idf scores: \\n', tf_idf_scores[:top_n])\n",
    "\n",
    "\n",
    "print('idf values: \\n', sorted(list(zip(feature_array,vectorizer.idf_,)),\n",
    "       key = lambda x: x[1], reverse=True)[:top_n])\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(docs_on_tokens[0:top_n])\n",
    "feature_array = vectorizer.get_feature_names()\n",
    "print('Frequency: \\n', sorted(list(zip(vectorizer.get_feature_names(), \n",
    "                                         X.sum(0).getA1())),\n",
    "                            key=lambda x: x[1], reverse=True)[:top_n])       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\"This is very strange\",\n",
    "          \"This is very nice\"]\n",
    "vectorizer = TfidfVectorizer(norm='l2')\n",
    "corpus = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dict(zip(vectorizer.vocabulary_, vectorizer.idf_)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.link.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"pt\"\n",
    "max_ngram_size = 3\n",
    "deduplication_thresold = 0.9\n",
    "deduplication_algo = 'seqm'\n",
    "windowSize = 1\n",
    "numOfKeywords = 5\n",
    "\n",
    "custom_kw_extractor = yake.KeywordExtractor(\n",
    "    lan=language, \n",
    "    n=max_ngram_size, \n",
    "    dedupLim=deduplication_thresold, \n",
    "    dedupFunc=deduplication_algo, \n",
    "    windowsSize=windowSize, \n",
    "    top=numOfKeywords, \n",
    "    features=None\n",
    ")\n",
    "keywords = custom_kw_extractor.extract_keywords(docs[0])\n",
    "\n",
    "for kw in keywords:\n",
    "    print(kw)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_on_docs = []\n",
    "for idx in range(len(data)):\n",
    "    keywords_on_docs.append(custom_kw_extractor.extract_keywords(simple_pipeline(Document(data.content.iloc[idx].lower())).cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_kw_extractor.extract_keywords(simple_pipeline(Document(data.content.iloc[0].lower())).cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/processed/docs_keywords.pickle', 'rb') as handle:\n",
    "        docs_keywords = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = []\n",
    "for keywords in docs_keywords[-50]:\n",
    "        t.append((keywords[0], model.predict(keywords[0])[0][0]))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter([v[1] for v in t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(docs_keywords[50][-2][0])[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=docs_on_tokens, vector_size=100, window=5, min_count=1, workers=4, sg=0, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar('rei', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity('homen', 'rei')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN, KMeans, MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/processed/words_embedded.pickle', 'rb') as handle:\n",
    "    words_emb = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words_emb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [val[0] for val in words_emb]\n",
    "ks = range(2, 12)\n",
    "results = {}\n",
    "for k in ks: \n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans.fit(X)\n",
    "    results[k] = silhouette_score(X, kmeans.labels_)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_preds.labels_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=10, random_state=0)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = MiniBatchKMeans(n_clusters=20,\n",
    "                         random_state=0,\n",
    "                         batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distortions = []\n",
    "cluster_numbers = range(2, 20)\n",
    "for k in cluster_numbers:\n",
    "    k_means = KMeans(n_clusters=k, random_state=42)\n",
    "    k_means.fit(X)\n",
    "    distortions.append(sum(np.min(cdist(X, k_means.cluster_centers_, 'euclidean'), axis=1)) / len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_line = [cluster_numbers[0], cluster_numbers[-1]]\n",
    "Y_line = [distortions[0], distortions[-1]]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(cluster_numbers, distortions, 'b-')\n",
    "plt.plot(X_line, Y_line, 'r')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()\n",
    "res['Word'] = [val[1] for val in words_emb]\n",
    "res['Emb'] = [val[0] for val in words_emb]\n",
    "res['Concept'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.Concept.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[res.Concept == 8].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "model = gensim.models.Word2Vec.load('../models/trained/word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.wv.most_similar('furto', topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for concept in np.unique(kmeans_preds.labels_):\n",
    "    print('Concept:', concept)\n",
    "    print(model.wv.most_similar(positive=[np.mean(res[res.Concept==concept]['Emb'])], topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format('../models/trained/fasttext-sentiment.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.most_similar('furto', topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for concept in np.unique(kmeans_preds.labels_):\n",
    "    print('Concept:', concept)\n",
    "    print(model.most_similar(positive=[np.mean(res[res.Concept==concept]['Emb'])], topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "model = fasttext.load_model('../models/trained/fasttext-sentiment.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.get_nearest_neighbors('desporto'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all words from model\n",
    "words = model.get_words()\n",
    "\n",
    "with open('../models/trained/fasttext-sentiment.vec','w') as file_out:\n",
    "    \n",
    "    # the first line must contain number of total words and vector dimension\n",
    "    file_out.write(str(len(words)) + \" \" + str(model.get_dimension()) + \"\\n\")\n",
    "\n",
    "    # line by line, you append vectors to VEC file\n",
    "    for w in words:\n",
    "        v = model.get_word_vector(w)\n",
    "        vstr = \"\"\n",
    "        for vi in v:\n",
    "            vstr += \" \" + str(vi)\n",
    "        try:\n",
    "            file_out.write(w + vstr+'\\n')\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for concept in np.unique(kmeans_preds.labels_):\n",
    "    print('Concept:', concept)\n",
    "    print(model.most_similar(positive=[np.mean(res[res.Concept==concept]['Emb'])], topn=10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "nlp = spacy.load(\"pt_core_news_lg\")\n",
    "nlp.add_pipe('spacytextblob')\n",
    "text = 'Este restaurante é uma vergonha!'\n",
    "doc = nlp(text)\n",
    "doc._.blob.polarity                         # Polarity: -0.125\n",
    "doc._.blob.subjectivity                        # Subjectivity: 0.9\n",
    "doc._.blob.sentiment_assessments.assessments   # Assessments: [(['really', 'horrible'], -1.0, 1.0, None), (['worst', '!'], -1.0, 1.0, None), (['really', 'good'], 0.7, 0.6000000000000001, None), (['happy'], 0.8, 1.0, None)]\n",
    "doc._.blob.ngrams()                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc._.blob.polarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "from textblob import TextBlob\n",
    "\n",
    "nlp = spacy.load(\"pt_core_news_lg\")\n",
    "nlp.add_pipe('spacytextblob')\n",
    "text = 'mau'\n",
    "doc = nlp(text)\n",
    "doc._.blob.polarity                            # Polarity: -0.125\n",
    "doc._.blob.subjectivity                        # Subjectivity: 0.9\n",
    "doc._.blob.sentiment_assessments.assessments   # Assessments: [(['really', 'horrible'], -1.0, 1.0, None), (['worst', '!'], -1.0, 1.0, None), (['really', 'good'], 0.7, 0.6000000000000001, None), (['happy'], 0.8, 1.0, None)]\n",
    "#doc._.blob.ngrams()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc._.blob.sentiment_assessments.assessments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/external_corpus/concatenated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(val):\n",
    "    if val < 3:\n",
    "        return 'Negative'\n",
    "    elif val == 3:\n",
    "        return 'Neutral'\n",
    "    elif val > 3:\n",
    "        return 'Positive'\n",
    "\n",
    "df['sentiment'] = df['rating'].apply(lambda val : sentiment(val))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dataset'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.sentiment == 'Neutral']['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.dataset.isin(['olist', 'b2w'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rating.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.polarity.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['polarity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [(ast.literal_eval(doc), r) for doc, r in zip(df['review_text_tokenized'].to_list(), df['sentiment'].tolist())]\n",
    "print(len(reviews))\n",
    "data = [(doc, r) for doc, r in reviews if len(doc) > 0]\n",
    "print(len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([' '.join(val[0]) for val in data])\n",
    "Y = np.array([val[1] for val in data])\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=0)\n",
    "for train_index, test_index in sss.split(X, Y ):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import linear_model\n",
    "from scipy.sparse import vstack, hstack\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = TfidfVectorizer()\n",
    "X_train_ = count_vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nb=naive_bayes.BernoulliNB()\n",
    "#nb.fit(X_train,y_train)\n",
    "#prob=nb.feature_log_prob_ #index 0 is positive\n",
    "\n",
    "#r=prob[0]-prob[1]\n",
    "\n",
    "#print('Weighing features')\n",
    "#X_train=[x.multiply(r).tocsr() for x in X_train_NB]\n",
    "#X_train=vstack(X_train)\n",
    "\n",
    "X_test_=count_vect.transform(X_test)\n",
    "#X_test=[x.multiply(r).tocsr() for x in X_test_pre]\n",
    "#X_test=vstack(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training classifier')\n",
    "\n",
    "svc = linear_model.LogisticRegression()\n",
    "svc.fit(X_train_,y_train)\n",
    "\n",
    "print('Testing classifier')\n",
    "print('Accuracy=', svc.score(X_test_, y_test)*100)\n",
    "print(classification_report(y_test, svc.predict(X_test_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = linear_model.SGDClassifier(loss='hinge', class_weight='balanced')\n",
    "svc.fit(X_train_, y_train)\n",
    "\n",
    "print('Testing classifier')\n",
    "print('Accuracy=',svc.score(X_test_, y_test)*100)\n",
    "print(classification_report(y_test, svc.predict(X_test_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame() \n",
    "df_train['sentiment'] = y_train\n",
    "df_train['review'] = X_train\n",
    "\n",
    "df_train['sentiment'] = df_train['sentiment'].apply(lambda val: f'__label__{val}')\n",
    "\n",
    "np.savetxt('olist-train.txt', df_train.values, fmt = \"%s\")\n",
    "\n",
    "print(df_train.shape)\n",
    "\n",
    "df_test = pd.DataFrame() \n",
    "df_test['sentiment'] = y_test\n",
    "df_test['review'] = X_test\n",
    "\n",
    "df_test['sentiment'] = df_test['sentiment'].apply(lambda val: f'__label__{val}')\n",
    "\n",
    "np.savetxt('olist-test.txt', df_test.values, fmt = \"%s\")\n",
    "\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(input=\"olist-train.txt\", lr=0.05, epoch=50, wordNgrams=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.test(\"olist-train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.test(\"olist-test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Pred'] = df_test['review'].apply(lambda val: model.predict(val)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(df_test['sentiment'], df_test['Pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ced3be9d1c63e918c342e50044be0791acd9298dca62153cfbef56e0b5c2b15"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
