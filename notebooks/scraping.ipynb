{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Porto'\n",
    "websites = 'expresso.pt'\n",
    "max_items = 2000\n",
    "from_ = '2021'\n",
    "to_ = '2022'\n",
    "link = f\"https://arquivo.pt/textsearch?versionHistory={websites}&maxItems={max_items}&dedupValue=1&prettyPrint=true&from={from_}&to={to_}\"\n",
    "f = requests.get(link)\n",
    "df = json.loads(f.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(s['title'], s['tstamp']) for s in df['response_items']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = [\n",
    "    \"Lisboa\",\n",
    "    \"Porto\",\n",
    "    \"Setúbal\",\n",
    "    \"Braga\",\n",
    "    \"Aveiro\",\n",
    "    \"Faro\",\n",
    "    \"Leiria\",\n",
    "    \"Santarém\",\n",
    "    \"Coimbra\",\n",
    "    \"Viseu\",\n",
    "    \"Viana do Castelo\",\n",
    "    \"Vila Real\",\n",
    "    \"Castelo Branco\",\n",
    "    \"Évora\",\n",
    "    \"Beja\",\n",
    "    \"Guarda\",\n",
    "    \"Bragança\",\n",
    "    \"Portalegre\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Porto'\n",
    "#websites = 'expresso.pt,publico.pt,jn.pt,dn.pt,cmjornal.pt,sol.sapo.pt,visao.sapo.pt'\n",
    "websites = 'nit.pt'\n",
    "max_items = 2000\n",
    "from_ = '1996'\n",
    "to_ = '2022'\n",
    "link = f\"https://arquivo.pt/textsearch?q={query}&siteSearch={websites}&maxItems={max_items}&dedupValue=1&prettyPrint=true&from={from_}&to={to_}\"\n",
    "f = requests.get(link)\n",
    "df = json.loads(f.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "newspapers = ['expresso.pt' ,'publico.pt', 'jn.pt', 'dn.pt', 'cmjornal.pt', 'sol.sapo.pt', 'visao.sapo.pt', 'jornaldenegocios.pt', 'observador.pt']\n",
    "others = ['turismodeportugal.pt', 'nit.pt']\n",
    "sources = newspapers + others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_items = 2000\n",
    "from_ = 1996\n",
    "to_ = 2023\n",
    "\n",
    "columns=['city', 'title', 'content', 'year', 'tstamp', 'link']\n",
    "\n",
    "data = pd.DataFrame(columns=columns)\n",
    "for city in cities:\n",
    "    for year in range(from_, to_):\n",
    "        \n",
    "        link = f\"https://arquivo.pt/textsearch?q={city}&siteSearch={','.join(sources)} \\\n",
    "            &maxItems={max_items}&dedupValue=1&prettyPrint=true&from={str(year)}&to={str(year+1)}\"\n",
    "        \n",
    "        try:\n",
    "        \n",
    "            r = requests.get(link)\n",
    "            payload = json.loads(r.text)['response_items']\n",
    "        \n",
    "            for idx, article in enumerate(payload):\n",
    "                \n",
    "                time.sleep(1)\n",
    "    \n",
    "                data = pd.concat([data, pd.DataFrame({\n",
    "                    'city': city, 'title': article['title'], 'content': requests.get(article['linkToExtractedText']).text, \n",
    "                    'year': year, 'tstamp': article['tstamp'], 'link': article['linkToArchive']}, index=[idx])\n",
    "                ], ignore_index=True)\n",
    "        \n",
    "        except Exception as e:\n",
    "            #print(e)\n",
    "            data = pd.concat([data, pd.DataFrame({\n",
    "                    'city': city, 'title': None, 'content': None, \n",
    "                    'year': year, 'tstamp': None, 'link': None\n",
    "                    }, index=[idx])\n",
    "            ], ignore_index=True)\n",
    "\n",
    "data.to_csv('../data/scraping_data.csv', index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/scraping_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>year</th>\n",
       "      <th>tstamp</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>POL | Local Lisboa</td>\n",
       "      <td>POL | Local Lisboa SECÇÕES 1ª Página Destaque ...</td>\n",
       "      <td>1999</td>\n",
       "      <td>19991111042737</td>\n",
       "      <td>https://arquivo.pt/wayback/19991111042737/http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>JN Editorial - Text57</td>\n",
       "      <td>JN Editorial - Text57 26 milhões para dar casa...</td>\n",
       "      <td>1999</td>\n",
       "      <td>19990822002536</td>\n",
       "      <td>https://arquivo.pt/wayback/19990822002536/http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>Outras Paginas</td>\n",
       "      <td>Outras Paginas 11 de Novembro de 1999 Igreja d...</td>\n",
       "      <td>1999</td>\n",
       "      <td>19991117215651</td>\n",
       "      <td>https://arquivo.pt/wayback/19991117215651/http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>JN Editorial - Texult1</td>\n",
       "      <td>JN Editorial - Texult1 Macau: Rão Kyao é o aut...</td>\n",
       "      <td>1999</td>\n",
       "      <td>19991118004529</td>\n",
       "      <td>https://arquivo.pt/wayback/19991118004529/http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lisboa</td>\n",
       "      <td>PÚBLICONLINE-Os Destaques da Primeira Página</td>\n",
       "      <td>PÚBLICONLINE-Os Destaques da Primeira Página S...</td>\n",
       "      <td>1999</td>\n",
       "      <td>19991012235908</td>\n",
       "      <td>https://arquivo.pt/wayback/19991012235908/http...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     city                                         title  \\\n",
       "0  Lisboa                            POL | Local Lisboa   \n",
       "1  Lisboa                         JN Editorial - Text57   \n",
       "2  Lisboa                                Outras Paginas   \n",
       "3  Lisboa                        JN Editorial - Texult1   \n",
       "4  Lisboa  PÚBLICONLINE-Os Destaques da Primeira Página   \n",
       "\n",
       "                                             content  year          tstamp  \\\n",
       "0  POL | Local Lisboa SECÇÕES 1ª Página Destaque ...  1999  19991111042737   \n",
       "1  JN Editorial - Text57 26 milhões para dar casa...  1999  19990822002536   \n",
       "2  Outras Paginas 11 de Novembro de 1999 Igreja d...  1999  19991117215651   \n",
       "3  JN Editorial - Texult1 Macau: Rão Kyao é o aut...  1999  19991118004529   \n",
       "4  PÚBLICONLINE-Os Destaques da Primeira Página S...  1999  19991012235908   \n",
       "\n",
       "                                                link  \n",
       "0  https://arquivo.pt/wayback/19991111042737/http...  \n",
       "1  https://arquivo.pt/wayback/19990822002536/http...  \n",
       "2  https://arquivo.pt/wayback/19991117215651/http...  \n",
       "3  https://arquivo.pt/wayback/19991118004529/http...  \n",
       "4  https://arquivo.pt/wayback/19991012235908/http...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../data/scraping_data.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def article_scrapper(city, sources):\n",
    "\n",
    "    max_items = 10\n",
    "    from_ = 1996\n",
    "    to_ = 2023\n",
    "\n",
    "    columns=['city', 'title', 'content', 'year', 'tstamp', 'link']\n",
    "    data = pd.DataFrame(columns=columns)\n",
    "    for year in range(from_, to_):\n",
    "        \n",
    "        link = f\"https://arquivo.pt/textsearch?q={city}&siteSearch={','.join(sources)} \\\n",
    "            &maxItems={max_items}&dedupValue=1&prettyPrint=true&from={str(year)}&to={str(year+1)}\"\n",
    "        \n",
    "        try:\n",
    "        \n",
    "            r = requests.get(link)\n",
    "            payload = json.loads(r.text)['response_items']\n",
    "        \n",
    "            for idx, article in enumerate(payload):\n",
    "                \n",
    "                time.sleep(1)\n",
    "\n",
    "                data = pd.concat([data, pd.DataFrame({\n",
    "                    'city': city, 'title': article['title'], 'content': requests.get(article['linkToExtractedText']).text, \n",
    "                    'year': year, 'tstamp': article['tstamp'], 'link': article['linkToArchive']}, index=[idx])\n",
    "                ], ignore_index=True)\n",
    "        \n",
    "        except Exception as e:\n",
    "            \n",
    "            data = pd.concat([data, pd.DataFrame({\n",
    "                    'city': city, 'title': None, 'content': None, \n",
    "                    'year': year, 'tstamp': None, 'link': None\n",
    "                    }, index=[idx])\n",
    "            ], ignore_index=True)\n",
    "\n",
    "    data.to_csv(f'../data/scraping_data.csv', index=False)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.Parallel(n_jobs=-1)(\n",
    "        joblib.delayed(article_scrapper)(\n",
    "            city=city,\n",
    "            sources=sources,    \n",
    "        )\n",
    "        for city in cities\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/scraping_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lisboa              5363\n",
       "Porto               3835\n",
       "Coimbra             2080\n",
       "Braga               2047\n",
       "Guarda              1969\n",
       "Setúbal             1792\n",
       "Aveiro              1471\n",
       "Beja                1403\n",
       "Leiria              1344\n",
       "Bragança            1215\n",
       "Faro                1208\n",
       "Viseu               1188\n",
       "Vila Real           1104\n",
       "Santarém            1072\n",
       "Castelo Branco       958\n",
       "Viana do Castelo     943\n",
       "Évora                908\n",
       "Portalegre           859\n",
       "Name: city, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['city'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57e5980710ed742cfe72a4be488a9d6f7ea4c6a6f4082a5d701045bcd350c891"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('smart_archive-LyPfE8oW-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
